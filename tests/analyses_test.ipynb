{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:04:43.068504Z",
     "iopub.status.busy": "2025-10-16T17:04:43.068326Z",
     "iopub.status.idle": "2025-10-16T17:04:43.708525Z",
     "shell.execute_reply": "2025-10-16T17:04:43.707917Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:36.149913Z",
     "start_time": "2025-10-16T22:49:35.609070Z"
    }
   },
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Locate and add the package root\n",
    "cwd = Path.cwd().resolve()\n",
    "for parent in [cwd, *cwd.parents]:\n",
    "    if (parent / \"sociopathit\").exists():\n",
    "        ROOT = parent\n",
    "        break\n",
    "else:\n",
    "    raise FileNotFoundError(\"Could not locate the sociopathit package root.\")\n",
    "\n",
    "# Add to sys.path for imports\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "\n",
    "print(f\"Added to sys.path: {ROOT}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to sys.path: C:\\Users\\alecw\\OneDrive - University of Toronto\\Directives\\GITTYSBURG\\sociopathit\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "1rw3ktrs03g",
   "metadata": {},
   "source": [
    "# Sociopathit Analysis Modules - Comprehensive Test Suite\n",
    "\n",
    "This notebook demonstrates and tests all analysis modules in the sociopathit package.\n",
    "\n",
    "## ðŸ“š Table of Contents\n",
    "\n",
    "Click to jump to any section:\n",
    "\n",
    "1. **[Setup & Initialization](#setup)** - Import packages and configure environment\n",
    "2. **[Regression Models](#regression)** - OLS, Logit, Poisson, Multilevel\n",
    "3. **[Publication Tables](#pubtable)** - Proportion, Descriptive, Regression tables\n",
    "4. **[Descriptive Statistics](#descriptive)** - Correlations, Crosstabs, Group summaries\n",
    "5. **[Causal Inference](#causal)** - Propensity scores, DiD, IV regression\n",
    "6. **[Panel Data Models](#panel)** - Fixed effects, Random effects, First differences\n",
    "7. **[Machine Learning](#ml)** - Random Forest, Feature importance\n",
    "8. **[Stata .dta Files](#stata)** - Working with categorical variables\n",
    "9. **[Text Analysis](#textanalysis)** - NLP, topic modeling, complexity scores, similarity\n",
    "10. **[Network Data](#network)** - Edge lists, adjacency matrices, co-occurrence, bipartite networks\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸš€ Quick Start\n",
    "\n",
    "```python\n",
    "# Example: Run a regression with categorical variables from .dta\n",
    "from sociopathit.data.loading import load_stata\n",
    "from sociopathit.analyses.regress import ols\n",
    "\n",
    "df = load_stata('survey.dta', convert_categoricals=True)\n",
    "model = ols(df, 'outcome', ['age', 'income', 'education'], robust=True)\n",
    "print(model.summary())\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ogqefjkylzc",
   "metadata": {},
   "source": [
    "<a id='setup'></a>\n",
    "## 1. Setup & Initialization\n",
    "\n",
    "Initialize the environment and import core packages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section1",
   "metadata": {},
   "source": [
    "<a id='regression'></a>\n",
    "# 2. Regression Models\n",
    "\n",
    "Test OLS, Logit, Poisson regression with the `regress` module."
   ]
  },
  {
   "cell_type": "code",
   "id": "regress1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:04:43.711050Z",
     "iopub.status.busy": "2025-10-16T17:04:43.710819Z",
     "iopub.status.idle": "2025-10-16T17:04:59.504255Z",
     "shell.execute_reply": "2025-10-16T17:04:59.503643Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:47.251504Z",
     "start_time": "2025-10-16T22:49:36.453442Z"
    }
   },
   "source": [
    "import importlib\n",
    "from sociopathit.analyses import regress as regress_module\n",
    "\n",
    "importlib.reload(regress_module)\n",
    "from sociopathit.analyses.regress import ols, logit, poisson, RegressionModel, compare_models\n",
    "\n",
    "# Simulate data for regression\n",
    "np.random.seed(42)\n",
    "n = 200\n",
    "df_regress = pd.DataFrame({\n",
    "    'age': np.random.normal(45, 15, n),\n",
    "    'income': np.random.normal(50000, 20000, n),\n",
    "    'education': np.random.choice([12, 14, 16, 18], n),\n",
    "    'satisfaction': np.random.normal(7, 2, n),\n",
    "    'employed': np.random.choice([0, 1], n, p=[0.2, 0.8]),\n",
    "    'count_events': np.random.poisson(3, n),\n",
    "    'weight': np.random.uniform(0.5, 1.5, n)\n",
    "})\n",
    "\n",
    "# Make satisfaction related to predictors\n",
    "df_regress['satisfaction'] = (\n",
    "    5 + \n",
    "    0.03 * df_regress['age'] + \n",
    "    0.00002 * df_regress['income'] + \n",
    "    0.2 * df_regress['education'] +\n",
    "    np.random.normal(0, 1, n)\n",
    ")\n",
    "\n",
    "print(df_regress.head())\n",
    "print(f\"\\nData shape: {df_regress.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         age        income  education  satisfaction  employed  count_events  \\\n",
      "0  52.450712  57155.747207         16     10.270672         1             2   \n",
      "1  42.926035  61215.690527         16      9.912903         1             1   \n",
      "2  54.715328  71661.024864         12      9.991937         1             0   \n",
      "3  67.845448  71076.041041         12      9.903556         1             4   \n",
      "4  41.487699  22446.612641         18     10.416234         1             3   \n",
      "\n",
      "     weight  \n",
      "0  1.484670  \n",
      "1  1.437388  \n",
      "2  0.543174  \n",
      "3  0.664815  \n",
      "4  0.631729  \n",
      "\n",
      "Data shape: (200, 7)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "koiym4wkv5f",
   "metadata": {},
   "source": [
    "### 2.1 Setup Test Data"
   ]
  },
  {
   "cell_type": "code",
   "id": "regress2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:04:59.506864Z",
     "iopub.status.busy": "2025-10-16T17:04:59.506267Z",
     "iopub.status.idle": "2025-10-16T17:04:59.520861Z",
     "shell.execute_reply": "2025-10-16T17:04:59.520171Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:47.302020Z",
     "start_time": "2025-10-16T22:49:47.282737Z"
    }
   },
   "source": [
    "# Test 1: OLS Regression\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 1: OLS Regression\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "model1 = ols(\n",
    "    df=df_regress,\n",
    "    outcome='satisfaction',\n",
    "    inputs=['age', 'income', 'education'],\n",
    "    robust=True\n",
    ")\n",
    "\n",
    "print(\"\\nModel Summary:\")\n",
    "print(model1.summary())\n",
    "\n",
    "print(\"\\nTidy Results:\")\n",
    "print(model1.get_tidy())\n",
    "\n",
    "print(\"\\nModel Statistics:\")\n",
    "print(model1.get_stats())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 1: OLS Regression\n",
      "============================================================\n",
      "\n",
      "Model Summary:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           satisfaction   R-squared:                       0.343\n",
      "Model:                            OLS   Adj. R-squared:                  0.332\n",
      "Method:                 Least Squares   F-statistic:                     43.58\n",
      "Date:                Thu, 16 Oct 2025   Prob (F-statistic):           1.27e-21\n",
      "Time:                        18:49:47   Log-Likelihood:                -272.29\n",
      "No. Observations:                 200   AIC:                             552.6\n",
      "Df Residuals:                     196   BIC:                             565.8\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:                  HC1                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          5.2328      0.489     10.691      0.000       4.273       6.192\n",
      "age            0.0281      0.005      5.456      0.000       0.018       0.038\n",
      "income      1.422e-05   3.45e-06      4.126      0.000    7.47e-06     2.1e-05\n",
      "education      0.2180      0.030      7.204      0.000       0.159       0.277\n",
      "==============================================================================\n",
      "Omnibus:                        1.462   Durbin-Watson:                   2.111\n",
      "Prob(Omnibus):                  0.481   Jarque-Bera (JB):                1.102\n",
      "Skew:                           0.117   Prob(JB):                        0.576\n",
      "Kurtosis:                       3.279   Cond. No.                     4.48e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC1)\n",
      "[2] The condition number is large, 4.48e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "Tidy Results:\n",
      "        term  estimate  std.error  statistic       p.value  conf.low  \\\n",
      "0      const  5.232790   0.489478  10.690550  1.127011e-26  4.273430   \n",
      "1        age  0.028139   0.005157   5.456454  4.857376e-08  0.018031   \n",
      "2     income  0.000014   0.000003   4.126085  3.689909e-05  0.000007   \n",
      "3  education  0.218017   0.030265   7.203650  5.862174e-13  0.158699   \n",
      "\n",
      "   conf.high  \n",
      "0   6.192149  \n",
      "1   0.038246  \n",
      "2   0.000021  \n",
      "3   0.277335  \n",
      "\n",
      "Model Statistics:\n",
      "{'N': 200, 'AIC': np.float64(552.580029868998), 'BIC': np.float64(565.7732993351902), 'Log-Likelihood': np.float64(-272.290014934499), 'R_squared': np.float64(0.34252933263973473), 'Adj_R_squared': np.float64(0.3324660060985062)}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "w72g957rqzm",
   "metadata": {},
   "source": [
    "### 2.2 OLS & Logistic Regression Tests"
   ]
  },
  {
   "cell_type": "code",
   "id": "regress3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:04:59.523444Z",
     "iopub.status.busy": "2025-10-16T17:04:59.523223Z",
     "iopub.status.idle": "2025-10-16T17:04:59.531574Z",
     "shell.execute_reply": "2025-10-16T17:04:59.531099Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:47.385177Z",
     "start_time": "2025-10-16T22:49:47.377099Z"
    }
   },
   "source": [
    "# Test 2: Weighted OLS Regression\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 2: Weighted OLS Regression\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "model2 = ols(\n",
    "    df=df_regress,\n",
    "    outcome='satisfaction',\n",
    "    inputs=['age', 'income', 'education'],\n",
    "    weight='weight',\n",
    "    robust=True\n",
    ")\n",
    "\n",
    "print(\"\\nTidy Results (Weighted):\")\n",
    "print(model2.get_tidy())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 2: Weighted OLS Regression\n",
      "============================================================\n",
      "\n",
      "Tidy Results (Weighted):\n",
      "        term  estimate  std.error  statistic       p.value  conf.low  \\\n",
      "0      const  5.165550   0.550893   9.376689  6.807718e-21  4.085820   \n",
      "1        age  0.027861   0.005502   5.063826  4.109257e-07  0.017078   \n",
      "2     income  0.000015   0.000004   3.976676  6.988537e-05  0.000008   \n",
      "3  education  0.219408   0.033506   6.548376  5.816620e-11  0.153738   \n",
      "\n",
      "   conf.high  \n",
      "0   6.245280  \n",
      "1   0.038645  \n",
      "2   0.000022  \n",
      "3   0.285078  \n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "regress4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:04:59.533539Z",
     "iopub.status.busy": "2025-10-16T17:04:59.533312Z",
     "iopub.status.idle": "2025-10-16T17:04:59.591546Z",
     "shell.execute_reply": "2025-10-16T17:04:59.590701Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:47.500374Z",
     "start_time": "2025-10-16T22:49:47.468752Z"
    }
   },
   "source": [
    "# Test 3: Logistic Regression\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 3: Logistic Regression\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "model3 = logit(\n",
    "    df=df_regress,\n",
    "    outcome='employed',\n",
    "    inputs=['age', 'education'],\n",
    "    robust=True\n",
    ")\n",
    "\n",
    "print(\"\\nLogistic Regression Results:\")\n",
    "print(model3.get_tidy())\n",
    "\n",
    "print(\"\\nModel Statistics:\")\n",
    "print(model3.get_stats())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 3: Logistic Regression\n",
      "============================================================\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.495807\n",
      "         Iterations 5\n",
      "\n",
      "Logistic Regression Results:\n",
      "        term  estimate  std.error  statistic   p.value  conf.low  conf.high\n",
      "0      const  0.949878   1.411842   0.672793  0.501079 -1.817283   3.717038\n",
      "1        age -0.013852   0.012969  -1.068082  0.285483 -0.039271   0.011567\n",
      "2  education  0.072462   0.086165   0.840969  0.400366 -0.096418   0.241342\n",
      "\n",
      "Model Statistics:\n",
      "{'N': 200, 'AIC': np.float64(204.3227910665525), 'BIC': np.float64(214.2177431661966), 'Log-Likelihood': np.float64(-99.16139553327625), 'Pseudo_R_squared': np.float64(0.009183500482258689)}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "regress5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:04:59.594572Z",
     "iopub.status.busy": "2025-10-16T17:04:59.594259Z",
     "iopub.status.idle": "2025-10-16T17:04:59.607961Z",
     "shell.execute_reply": "2025-10-16T17:04:59.607045Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:47.570992Z",
     "start_time": "2025-10-16T22:49:47.557319Z"
    }
   },
   "source": [
    "# Test 4: Poisson Regression\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 4: Poisson Regression\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "model4 = poisson(\n",
    "    df=df_regress,\n",
    "    outcome='count_events',\n",
    "    inputs=['age', 'income'],\n",
    "    robust=True\n",
    ")\n",
    "\n",
    "print(\"\\nPoisson Regression Results:\")\n",
    "print(model4.get_tidy())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 4: Poisson Regression\n",
      "============================================================\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 149651730807018435982530780671770624000.000000\n",
      "         Iterations: 35\n",
      "\n",
      "Poisson Regression Results:\n",
      "     term   estimate     std.error     statistic   p.value      conf.low  \\\n",
      "0   const -32.962559  1.658551e+07 -1.987431e-06  0.999998 -3.250703e+07   \n",
      "1     age  -0.005334  1.996745e+05 -2.671477e-08  1.000000 -3.913549e+05   \n",
      "2  income   0.000995  4.396441e+01  2.263666e-05  0.999982 -8.616766e+01   \n",
      "\n",
      "      conf.high  \n",
      "0  3.250696e+07  \n",
      "1  3.913549e+05  \n",
      "2  8.616965e+01  \n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "regress6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:04:59.612740Z",
     "iopub.status.busy": "2025-10-16T17:04:59.612543Z",
     "iopub.status.idle": "2025-10-16T17:04:59.625088Z",
     "shell.execute_reply": "2025-10-16T17:04:59.624402Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:47.644808Z",
     "start_time": "2025-10-16T22:49:47.632317Z"
    }
   },
   "source": [
    "# Test 5: Model Comparison\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 5: Model Comparison\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create two models with different specifications\n",
    "model_simple = ols(df_regress, 'satisfaction', 'age')\n",
    "model_full = ols(df_regress, 'satisfaction', ['age', 'income', 'education'])\n",
    "\n",
    "comparison = compare_models(model_simple, model_full)\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(comparison)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 5: Model Comparison\n",
      "============================================================\n",
      "\n",
      "Model Comparison:\n",
      "     Model                  Inputs    N         AIC         BIC  \\\n",
      "0  Model 1                     age  200  601.672931  608.269566   \n",
      "1  Model 2  age, income, education  200  552.580030  565.773299   \n",
      "\n",
      "   Log-Likelihood  R_squared  Adj_R_squared  \n",
      "0     -298.836465   0.142634       0.138304  \n",
      "1     -272.290015   0.342529       0.332466  \n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "regress7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:04:59.627928Z",
     "iopub.status.busy": "2025-10-16T17:04:59.627448Z",
     "iopub.status.idle": "2025-10-16T17:04:59.635240Z",
     "shell.execute_reply": "2025-10-16T17:04:59.634811Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:47.705877Z",
     "start_time": "2025-10-16T22:49:47.700581Z"
    }
   },
   "source": [
    "# Test 6: Predictions\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 6: Predictions\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "predictions = model1.predict()\n",
    "print(f\"\\nPredicted values (first 10): {predictions[:10]}\")\n",
    "\n",
    "# New data predictions\n",
    "new_data = pd.DataFrame({\n",
    "    'age': [30, 40, 50],\n",
    "    'income': [40000, 50000, 60000],\n",
    "    'education': [16, 16, 18]\n",
    "})\n",
    "new_predictions = model1.predict(new_data)\n",
    "print(f\"\\nPredictions for new data: {new_predictions}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 6: Predictions\n",
      "============================================================\n",
      "\n",
      "Predicted values (first 10): 0    11.009774\n",
      "1    10.799499\n",
      "2    10.407709\n",
      "3    10.768853\n",
      "4    10.643722\n",
      "5    10.332796\n",
      "6    11.075364\n",
      "7    11.604443\n",
      "8     9.774625\n",
      "9    11.151095\n",
      "dtype: float64\n",
      "\n",
      "Predictions for new data: 0    10.134068\n",
      "1    10.557665\n",
      "2    11.417297\n",
      "dtype: float64\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "regress8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:04:59.637636Z",
     "iopub.status.busy": "2025-10-16T17:04:59.637297Z",
     "iopub.status.idle": "2025-10-16T17:04:59.677018Z",
     "shell.execute_reply": "2025-10-16T17:04:59.654691Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:47.769282Z",
     "start_time": "2025-10-16T22:49:47.759694Z"
    }
   },
   "source": [
    "# Test 7: VIF (Multicollinearity Check)\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 7: Variance Inflation Factors\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "vif_results = model1.vif()\n",
    "print(\"\\nVIF Values:\")\n",
    "print(vif_results)\n",
    "print(\"\\nNote: VIF > 10 indicates potential multicollinearity\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 7: Variance Inflation Factors\n",
      "============================================================\n",
      "\n",
      "VIF Values:\n",
      "    Variable       VIF\n",
      "1        age  1.012199\n",
      "2     income  1.020473\n",
      "3  education  1.013279\n",
      "\n",
      "Note: VIF > 10 indicates potential multicollinearity\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "section2",
   "metadata": {},
   "source": [
    "<a id='pubtable'></a>\n",
    "# 3. Publication Tables\n",
    "\n",
    "Create publication-ready tables with the `pubtable` module."
   ]
  },
  {
   "cell_type": "code",
   "id": "pubtable1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:04:59.680603Z",
     "iopub.status.busy": "2025-10-16T17:04:59.680323Z",
     "iopub.status.idle": "2025-10-16T17:04:59.695369Z",
     "shell.execute_reply": "2025-10-16T17:04:59.694646Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:47.870092Z",
     "start_time": "2025-10-16T22:49:47.856930Z"
    }
   },
   "source": [
    "import importlib\n",
    "from sociopathit.analyses import pubtable as pubtable_module\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "importlib.reload(pubtable_module)\n",
    "from sociopathit.analyses.pubtable import (\n",
    "    proportion_table, \n",
    "    descriptive_table, \n",
    "    regression_table,\n",
    "    save_table\n",
    ")\n",
    "\n",
    "# Simulate survey data\n",
    "np.random.seed(42)\n",
    "n = 300\n",
    "df_survey = pd.DataFrame({\n",
    "    'gender': np.random.choice(['Male', 'Female'], n),\n",
    "    'education': np.random.choice(['High School', 'Bachelor', 'Graduate'], n),\n",
    "    'response': np.random.choice(['Yes', 'No', 'Maybe'], n, p=[0.4, 0.4, 0.2]),\n",
    "    'age': np.random.normal(40, 15, n),\n",
    "    'income': np.random.normal(55000, 25000, n),\n",
    "    'satisfaction': np.random.normal(7, 2, n),\n",
    "    'weight': np.random.uniform(0.8, 1.2, n)\n",
    "})\n",
    "\n",
    "print(df_survey.head())\n",
    "print(f\"\\nData shape: {df_survey.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gender    education response        age         income  satisfaction  \\\n",
      "0    Male  High School       No  30.743644  106059.910568      7.746792   \n",
      "1  Female  High School    Maybe  21.117369   67129.377631      8.014032   \n",
      "2    Male     Graduate       No  57.832015   58632.405994      7.396579   \n",
      "3    Male     Bachelor      Yes  39.380374   97839.349771      6.480788   \n",
      "4    Male     Bachelor      Yes  42.609495   80253.424981      7.361291   \n",
      "\n",
      "     weight  \n",
      "0  1.190396  \n",
      "1  1.066940  \n",
      "2  0.804171  \n",
      "3  0.902165  \n",
      "4  0.904285  \n",
      "\n",
      "Data shape: (300, 7)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "pubtable2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:04:59.697774Z",
     "iopub.status.busy": "2025-10-16T17:04:59.697567Z",
     "iopub.status.idle": "2025-10-16T17:04:59.709908Z",
     "shell.execute_reply": "2025-10-16T17:04:59.709147Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:47.966978Z",
     "start_time": "2025-10-16T22:49:47.954053Z"
    }
   },
   "source": [
    "# Test 1: Proportion Table (One-way)\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 1: One-Way Proportion Table\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "html1 = proportion_table(\n",
    "    df=df_survey,\n",
    "    row_var='response',\n",
    "    title='Distribution of Responses',\n",
    "    ci=True,\n",
    "    show_n=True\n",
    ")\n",
    "\n",
    "display(HTML(html1))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 1: One-Way Proportion Table\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <style>\n",
       "        .pubtable {\n",
       "            font-family: 'Times New Roman', Times, serif;\n",
       "            border-collapse: collapse;\n",
       "            margin: 20px auto;\n",
       "            font-size: 11pt;\n",
       "            width: auto;\n",
       "            max-width: 100%;\n",
       "        }\n",
       "        .pubtable th {\n",
       "            border-top: 2px solid #000;\n",
       "            border-bottom: 1px solid #000;\n",
       "            padding: 8px 12px;\n",
       "            text-align: left;\n",
       "            font-weight: bold;\n",
       "        }\n",
       "        .pubtable td {\n",
       "            padding: 6px 12px;\n",
       "            text-align: left;\n",
       "        }\n",
       "        .pubtable tbody tr:last-child td {\n",
       "            border-bottom: 2px solid #000;\n",
       "        }\n",
       "        .pubtable .number {\n",
       "            text-align: right;\n",
       "            font-feature-settings: 'tnum';\n",
       "        }\n",
       "        .pubtable caption {\n",
       "            caption-side: top;\n",
       "            text-align: left;\n",
       "            font-weight: bold;\n",
       "            padding-bottom: 10px;\n",
       "            font-size: 12pt;\n",
       "        }\n",
       "        .pubtable .note {\n",
       "            font-size: 9pt;\n",
       "            font-style: italic;\n",
       "            padding-top: 5px;\n",
       "            border-top: none;\n",
       "        }\n",
       "        .pubtable .indent {\n",
       "            padding-left: 24px;\n",
       "        }\n",
       "    </style>\n",
       "    <table class=\"pubtable\"><caption>Distribution of Responses</caption><thead><tr><th class=\"\">response</th><th class=\"number\">%</th><th class=\"number\">95% CI</th><th class=\"number\">n</th></tr></thead><tbody><tr><td class=\"\">Maybe</td><td class=\"number\">18.0</td><td class=\"number\">[10.0, 30.3]</td><td class=\"number\">54</td></tr><tr><td class=\"\">No</td><td class=\"number\">42.0</td><td class=\"number\">[33.7, 50.7]</td><td class=\"number\">126</td></tr><tr><td class=\"\">Yes</td><td class=\"number\">40.0</td><td class=\"number\">[31.7, 48.9]</td><td class=\"number\">120</td></tr></tbody></table><p class=\"note\" style=\"margin-left: 20px; font-size: 9pt; font-style: italic;\">Note: 95% confidence intervals shown.</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "pubtable3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:04:59.713019Z",
     "iopub.status.busy": "2025-10-16T17:04:59.712664Z",
     "iopub.status.idle": "2025-10-16T17:04:59.728505Z",
     "shell.execute_reply": "2025-10-16T17:04:59.728030Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:48.132244Z",
     "start_time": "2025-10-16T22:49:48.120947Z"
    }
   },
   "source": [
    "# Test 2: Proportion Table (Cross-tabulation)\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 2: Cross-Tabulation Proportion Table\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "html2 = proportion_table(\n",
    "    df=df_survey,\n",
    "    row_var='response',\n",
    "    col_var='gender',\n",
    "    title='Response by Gender',\n",
    "    decimals=1\n",
    ")\n",
    "\n",
    "display(HTML(html2))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 2: Cross-Tabulation Proportion Table\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <style>\n",
       "        .pubtable {\n",
       "            font-family: 'Times New Roman', Times, serif;\n",
       "            border-collapse: collapse;\n",
       "            margin: 20px auto;\n",
       "            font-size: 11pt;\n",
       "            width: auto;\n",
       "            max-width: 100%;\n",
       "        }\n",
       "        .pubtable th {\n",
       "            border-top: 2px solid #000;\n",
       "            border-bottom: 1px solid #000;\n",
       "            padding: 8px 12px;\n",
       "            text-align: left;\n",
       "            font-weight: bold;\n",
       "        }\n",
       "        .pubtable td {\n",
       "            padding: 6px 12px;\n",
       "            text-align: left;\n",
       "        }\n",
       "        .pubtable tbody tr:last-child td {\n",
       "            border-bottom: 2px solid #000;\n",
       "        }\n",
       "        .pubtable .number {\n",
       "            text-align: right;\n",
       "            font-feature-settings: 'tnum';\n",
       "        }\n",
       "        .pubtable caption {\n",
       "            caption-side: top;\n",
       "            text-align: left;\n",
       "            font-weight: bold;\n",
       "            padding-bottom: 10px;\n",
       "            font-size: 12pt;\n",
       "        }\n",
       "        .pubtable .note {\n",
       "            font-size: 9pt;\n",
       "            font-style: italic;\n",
       "            padding-top: 5px;\n",
       "            border-top: none;\n",
       "        }\n",
       "        .pubtable .indent {\n",
       "            padding-left: 24px;\n",
       "        }\n",
       "    </style>\n",
       "    <table class=\"pubtable\"><caption>Response by Gender</caption><thead><tr><th class=\"\">response</th><th class=\"number\">Female</th><th class=\"number\">Male</th></tr></thead><tbody><tr><td class=\"\">Maybe</td><td class=\"number\">20.8</td><td class=\"number\">15.2</td></tr><tr><td class=\"\">No</td><td class=\"number\">38.9</td><td class=\"number\">45.0</td></tr><tr><td class=\"\">Yes</td><td class=\"number\">40.3</td><td class=\"number\">39.7</td></tr></tbody></table><p class=\"note\" style=\"margin-left: 20px; font-size: 9pt; font-style: italic;\">Note: 95% confidence intervals shown.</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "pubtable4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:04:59.730729Z",
     "iopub.status.busy": "2025-10-16T17:04:59.730348Z",
     "iopub.status.idle": "2025-10-16T17:04:59.739779Z",
     "shell.execute_reply": "2025-10-16T17:04:59.739341Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:48.204905Z",
     "start_time": "2025-10-16T22:49:48.197692Z"
    }
   },
   "source": [
    "# Test 3: Weighted Proportion Table\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 3: Weighted Proportion Table\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "html3 = proportion_table(\n",
    "    df=df_survey,\n",
    "    row_var='education',\n",
    "    weight_var='weight',\n",
    "    title='Education Distribution (Weighted)',\n",
    "    ci=True,\n",
    "    show_n=True\n",
    ")\n",
    "\n",
    "display(HTML(html3))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 3: Weighted Proportion Table\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <style>\n",
       "        .pubtable {\n",
       "            font-family: 'Times New Roman', Times, serif;\n",
       "            border-collapse: collapse;\n",
       "            margin: 20px auto;\n",
       "            font-size: 11pt;\n",
       "            width: auto;\n",
       "            max-width: 100%;\n",
       "        }\n",
       "        .pubtable th {\n",
       "            border-top: 2px solid #000;\n",
       "            border-bottom: 1px solid #000;\n",
       "            padding: 8px 12px;\n",
       "            text-align: left;\n",
       "            font-weight: bold;\n",
       "        }\n",
       "        .pubtable td {\n",
       "            padding: 6px 12px;\n",
       "            text-align: left;\n",
       "        }\n",
       "        .pubtable tbody tr:last-child td {\n",
       "            border-bottom: 2px solid #000;\n",
       "        }\n",
       "        .pubtable .number {\n",
       "            text-align: right;\n",
       "            font-feature-settings: 'tnum';\n",
       "        }\n",
       "        .pubtable caption {\n",
       "            caption-side: top;\n",
       "            text-align: left;\n",
       "            font-weight: bold;\n",
       "            padding-bottom: 10px;\n",
       "            font-size: 12pt;\n",
       "        }\n",
       "        .pubtable .note {\n",
       "            font-size: 9pt;\n",
       "            font-style: italic;\n",
       "            padding-top: 5px;\n",
       "            border-top: none;\n",
       "        }\n",
       "        .pubtable .indent {\n",
       "            padding-left: 24px;\n",
       "        }\n",
       "    </style>\n",
       "    <table class=\"pubtable\"><caption>Education Distribution (Weighted)</caption><thead><tr><th class=\"\">education</th><th class=\"number\">%</th><th class=\"number\">95% CI</th><th class=\"number\">n</th></tr></thead><tbody><tr><td class=\"\">Bachelor</td><td class=\"number\">35.1</td><td class=\"number\">[26.6, 44.7]</td><td class=\"number\">104</td></tr><tr><td class=\"\">Graduate</td><td class=\"number\">31.0</td><td class=\"number\">[22.6, 41.0]</td><td class=\"number\">94</td></tr><tr><td class=\"\">High School</td><td class=\"number\">33.9</td><td class=\"number\">[25.4, 43.5]</td><td class=\"number\">102</td></tr></tbody></table><p class=\"note\" style=\"margin-left: 20px; font-size: 9pt; font-style: italic;\">Note: 95% confidence intervals shown.</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "pubtable5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:04:59.741891Z",
     "iopub.status.busy": "2025-10-16T17:04:59.741697Z",
     "iopub.status.idle": "2025-10-16T17:04:59.749149Z",
     "shell.execute_reply": "2025-10-16T17:04:59.748483Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:48.283993Z",
     "start_time": "2025-10-16T22:49:48.277472Z"
    }
   },
   "source": [
    "# Test 4: Descriptive Statistics Table\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 4: Descriptive Statistics Table\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "html4 = descriptive_table(\n",
    "    df=df_survey,\n",
    "    variables=['age', 'income', 'satisfaction'],\n",
    "    stats=['mean', 'sd', 'min', 'max', 'n'],\n",
    "    decimals=2,\n",
    "    title='Descriptive Statistics',\n",
    "    var_labels={'age': 'Age (years)', 'income': 'Annual Income ($)', 'satisfaction': 'Life Satisfaction'}\n",
    ")\n",
    "\n",
    "display(HTML(html4))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 4: Descriptive Statistics Table\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <style>\n",
       "        .pubtable {\n",
       "            font-family: 'Times New Roman', Times, serif;\n",
       "            border-collapse: collapse;\n",
       "            margin: 20px auto;\n",
       "            font-size: 11pt;\n",
       "            width: auto;\n",
       "            max-width: 100%;\n",
       "        }\n",
       "        .pubtable th {\n",
       "            border-top: 2px solid #000;\n",
       "            border-bottom: 1px solid #000;\n",
       "            padding: 8px 12px;\n",
       "            text-align: left;\n",
       "            font-weight: bold;\n",
       "        }\n",
       "        .pubtable td {\n",
       "            padding: 6px 12px;\n",
       "            text-align: left;\n",
       "        }\n",
       "        .pubtable tbody tr:last-child td {\n",
       "            border-bottom: 2px solid #000;\n",
       "        }\n",
       "        .pubtable .number {\n",
       "            text-align: right;\n",
       "            font-feature-settings: 'tnum';\n",
       "        }\n",
       "        .pubtable caption {\n",
       "            caption-side: top;\n",
       "            text-align: left;\n",
       "            font-weight: bold;\n",
       "            padding-bottom: 10px;\n",
       "            font-size: 12pt;\n",
       "        }\n",
       "        .pubtable .note {\n",
       "            font-size: 9pt;\n",
       "            font-style: italic;\n",
       "            padding-top: 5px;\n",
       "            border-top: none;\n",
       "        }\n",
       "        .pubtable .indent {\n",
       "            padding-left: 24px;\n",
       "        }\n",
       "    </style>\n",
       "    <table class=\"pubtable\"><caption>Descriptive Statistics</caption><thead><tr><th class=\"\">Variable</th><th class=\"number\">Mean</th><th class=\"number\">Sd</th><th class=\"number\">Min</th><th class=\"number\">Max</th><th class=\"number\">N</th></tr></thead><tbody><tr><td class=\"\">Age (years)</td><td class=\"number\">41.73</td><td class=\"number\">16.11</td><td class=\"number\">-1.77</td><td class=\"number\">84.64</td><td class=\"number\">300</td></tr><tr><td class=\"\">Annual Income ($)</td><td class=\"number\">57483.38</td><td class=\"number\">26825.21</td><td class=\"number\">-10246.04</td><td class=\"number\">134184.29</td><td class=\"number\">300</td></tr><tr><td class=\"\">Life Satisfaction</td><td class=\"number\">7.08</td><td class=\"number\">2.04</td><td class=\"number\">1.97</td><td class=\"number\">12.40</td><td class=\"number\">300</td></tr></tbody></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "pubtable6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:04:59.752163Z",
     "iopub.status.busy": "2025-10-16T17:04:59.751807Z",
     "iopub.status.idle": "2025-10-16T17:04:59.764475Z",
     "shell.execute_reply": "2025-10-16T17:04:59.763684Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:48.346191Z",
     "start_time": "2025-10-16T22:49:48.339287Z"
    }
   },
   "source": [
    "# Test 5: Grouped Descriptive Statistics\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 5: Grouped Descriptive Statistics\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "html5 = descriptive_table(\n",
    "    df=df_survey,\n",
    "    variables=['age', 'income'],\n",
    "    group_var='gender',\n",
    "    stats=['mean', 'sd', 'n'],\n",
    "    decimals=1,\n",
    "    title='Demographics by Gender'\n",
    ")\n",
    "\n",
    "display(HTML(html5))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 5: Grouped Descriptive Statistics\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <style>\n",
       "        .pubtable {\n",
       "            font-family: 'Times New Roman', Times, serif;\n",
       "            border-collapse: collapse;\n",
       "            margin: 20px auto;\n",
       "            font-size: 11pt;\n",
       "            width: auto;\n",
       "            max-width: 100%;\n",
       "        }\n",
       "        .pubtable th {\n",
       "            border-top: 2px solid #000;\n",
       "            border-bottom: 1px solid #000;\n",
       "            padding: 8px 12px;\n",
       "            text-align: left;\n",
       "            font-weight: bold;\n",
       "        }\n",
       "        .pubtable td {\n",
       "            padding: 6px 12px;\n",
       "            text-align: left;\n",
       "        }\n",
       "        .pubtable tbody tr:last-child td {\n",
       "            border-bottom: 2px solid #000;\n",
       "        }\n",
       "        .pubtable .number {\n",
       "            text-align: right;\n",
       "            font-feature-settings: 'tnum';\n",
       "        }\n",
       "        .pubtable caption {\n",
       "            caption-side: top;\n",
       "            text-align: left;\n",
       "            font-weight: bold;\n",
       "            padding-bottom: 10px;\n",
       "            font-size: 12pt;\n",
       "        }\n",
       "        .pubtable .note {\n",
       "            font-size: 9pt;\n",
       "            font-style: italic;\n",
       "            padding-top: 5px;\n",
       "            border-top: none;\n",
       "        }\n",
       "        .pubtable .indent {\n",
       "            padding-left: 24px;\n",
       "        }\n",
       "    </style>\n",
       "    <table class=\"pubtable\"><caption>Demographics by Gender</caption><thead><tr><th class=\"\">Variable</th><th class=\"\">Group</th><th class=\"number\">Mean</th><th class=\"number\">Sd</th><th class=\"number\">N</th></tr></thead><tbody><tr><td class=\"\">age</td><td class=\"\">Female</td><td class=\"number\">42.2</td><td class=\"number\">15.4</td><td class=\"number\">149</td></tr><tr><td class=\" indent\"></td><td class=\"\">Male</td><td class=\"number\">41.2</td><td class=\"number\">16.8</td><td class=\"number\">151</td></tr><tr><td class=\"\">income</td><td class=\"\">Female</td><td class=\"number\">57561.4</td><td class=\"number\">26690.6</td><td class=\"number\">149</td></tr><tr><td class=\" indent\"></td><td class=\"\">Male</td><td class=\"number\">57406.4</td><td class=\"number\">26957.1</td><td class=\"number\">151</td></tr></tbody></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "pubtable7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:04:59.767843Z",
     "iopub.status.busy": "2025-10-16T17:04:59.767441Z",
     "iopub.status.idle": "2025-10-16T17:04:59.786106Z",
     "shell.execute_reply": "2025-10-16T17:04:59.785594Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:48.401716Z",
     "start_time": "2025-10-16T22:49:48.391209Z"
    }
   },
   "source": [
    "# Test 6: Regression Table (Single Model)\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 6: Regression Table (Single Model)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Fit a model\n",
    "model_pub = ols(df_survey, 'satisfaction', ['age', 'income'])\n",
    "results_df = model_pub.get_tidy()\n",
    "\n",
    "html6 = regression_table(\n",
    "    models=results_df,\n",
    "    title='OLS Regression: Life Satisfaction',\n",
    "    show_se=True,\n",
    "    show_stars=True,\n",
    "    var_labels={'age': 'Age', 'income': 'Income', 'const': 'Intercept'},\n",
    "    stats_rows={\n",
    "        'N': [int(model_pub.get_stats()['N'])],\n",
    "        'R_squared': [model_pub.get_stats()['R_squared']]\n",
    "    }\n",
    ")\n",
    "\n",
    "display(HTML(html6))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 6: Regression Table (Single Model)\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <style>\n",
       "        .pubtable {\n",
       "            font-family: 'Times New Roman', Times, serif;\n",
       "            border-collapse: collapse;\n",
       "            margin: 20px auto;\n",
       "            font-size: 11pt;\n",
       "            width: auto;\n",
       "            max-width: 100%;\n",
       "        }\n",
       "        .pubtable th {\n",
       "            border-top: 2px solid #000;\n",
       "            border-bottom: 1px solid #000;\n",
       "            padding: 8px 12px;\n",
       "            text-align: left;\n",
       "            font-weight: bold;\n",
       "        }\n",
       "        .pubtable td {\n",
       "            padding: 6px 12px;\n",
       "            text-align: left;\n",
       "        }\n",
       "        .pubtable tbody tr:last-child td {\n",
       "            border-bottom: 2px solid #000;\n",
       "        }\n",
       "        .pubtable .number {\n",
       "            text-align: right;\n",
       "            font-feature-settings: 'tnum';\n",
       "        }\n",
       "        .pubtable caption {\n",
       "            caption-side: top;\n",
       "            text-align: left;\n",
       "            font-weight: bold;\n",
       "            padding-bottom: 10px;\n",
       "            font-size: 12pt;\n",
       "        }\n",
       "        .pubtable .note {\n",
       "            font-size: 9pt;\n",
       "            font-style: italic;\n",
       "            padding-top: 5px;\n",
       "            border-top: none;\n",
       "        }\n",
       "        .pubtable .indent {\n",
       "            padding-left: 24px;\n",
       "        }\n",
       "    </style>\n",
       "    <table class=\"pubtable\"><caption>OLS Regression: Life Satisfaction</caption><thead><tr><th class=\"\"></th><th class=\"number\">Model 1</th></tr></thead><tbody><tr><td class=\"\">Intercept</td><td class=\"number\">7.958***</td></tr><tr><td class=\" indent\"></td><td class=\"number\">(0.406)</td></tr><tr><td class=\"\">Age</td><td class=\"number\">-0.009</td></tr><tr><td class=\" indent\"></td><td class=\"number\">(0.008)</td></tr><tr><td class=\"\">Income</td><td class=\"number\">-0.000*</td></tr><tr><td class=\" indent\"></td><td class=\"number\">(0.000)</td></tr><tr><td class=\"\">N</td><td class=\"number\">300.00</td></tr><tr><td class=\"\">R_squared</td><td class=\"number\">0.02</td></tr></tbody></table><p class=\"note\" style=\"margin-left: 20px; font-size: 9pt; font-style: italic;\">Note: *** p<.001, ** p<.01, * p<.05</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "pubtable8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:04:59.788600Z",
     "iopub.status.busy": "2025-10-16T17:04:59.788133Z",
     "iopub.status.idle": "2025-10-16T17:04:59.807923Z",
     "shell.execute_reply": "2025-10-16T17:04:59.807166Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:48.472421Z",
     "start_time": "2025-10-16T22:49:48.457339Z"
    }
   },
   "source": [
    "# Test 7: Regression Table (Multiple Models)\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 7: Regression Table (Multiple Models)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Fit multiple models\n",
    "model_a = ols(df_survey, 'satisfaction', 'age')\n",
    "model_b = ols(df_survey, 'satisfaction', ['age', 'income'])\n",
    "\n",
    "html7 = regression_table(\n",
    "    models=[model_a.get_tidy(), model_b.get_tidy()],\n",
    "    model_names=['Model 1', 'Model 2'],\n",
    "    title='Regression Models Comparison',\n",
    "    show_se=True,\n",
    "    show_stars=True,\n",
    "    var_labels={'age': 'Age', 'income': 'Income', 'const': 'Intercept'},\n",
    "    stats_rows={\n",
    "        'N': [int(model_a.get_stats()['N']), int(model_b.get_stats()['N'])],\n",
    "        'R_squared': [model_a.get_stats()['R_squared'], model_b.get_stats()['R_squared']]\n",
    "    }\n",
    ")\n",
    "\n",
    "display(HTML(html7))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 7: Regression Table (Multiple Models)\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <style>\n",
       "        .pubtable {\n",
       "            font-family: 'Times New Roman', Times, serif;\n",
       "            border-collapse: collapse;\n",
       "            margin: 20px auto;\n",
       "            font-size: 11pt;\n",
       "            width: auto;\n",
       "            max-width: 100%;\n",
       "        }\n",
       "        .pubtable th {\n",
       "            border-top: 2px solid #000;\n",
       "            border-bottom: 1px solid #000;\n",
       "            padding: 8px 12px;\n",
       "            text-align: left;\n",
       "            font-weight: bold;\n",
       "        }\n",
       "        .pubtable td {\n",
       "            padding: 6px 12px;\n",
       "            text-align: left;\n",
       "        }\n",
       "        .pubtable tbody tr:last-child td {\n",
       "            border-bottom: 2px solid #000;\n",
       "        }\n",
       "        .pubtable .number {\n",
       "            text-align: right;\n",
       "            font-feature-settings: 'tnum';\n",
       "        }\n",
       "        .pubtable caption {\n",
       "            caption-side: top;\n",
       "            text-align: left;\n",
       "            font-weight: bold;\n",
       "            padding-bottom: 10px;\n",
       "            font-size: 12pt;\n",
       "        }\n",
       "        .pubtable .note {\n",
       "            font-size: 9pt;\n",
       "            font-style: italic;\n",
       "            padding-top: 5px;\n",
       "            border-top: none;\n",
       "        }\n",
       "        .pubtable .indent {\n",
       "            padding-left: 24px;\n",
       "        }\n",
       "    </style>\n",
       "    <table class=\"pubtable\"><caption>Regression Models Comparison</caption><thead><tr><th class=\"\"></th><th class=\"number\">Model 1</th><th class=\"number\">Model 2</th></tr></thead><tbody><tr><td class=\"\">Intercept</td><td class=\"number\">7.495***</td><td class=\"number\">7.958***</td></tr><tr><td class=\" indent\"></td><td class=\"number\">(0.348)</td><td class=\"number\">(0.406)</td></tr><tr><td class=\"\">Age</td><td class=\"number\">-0.010</td><td class=\"number\">-0.009</td></tr><tr><td class=\" indent\"></td><td class=\"number\">(0.008)</td><td class=\"number\">(0.008)</td></tr><tr><td class=\"\">Income</td><td class=\"number\">\u0014</td><td class=\"number\">-0.000*</td></tr><tr><td class=\" indent\"></td><td class=\"number\"></td><td class=\"number\">(0.000)</td></tr><tr><td class=\"\">N</td><td class=\"number\">300.00</td><td class=\"number\">300.00</td></tr><tr><td class=\"\">R_squared</td><td class=\"number\">0.01</td><td class=\"number\">0.02</td></tr></tbody></table><p class=\"note\" style=\"margin-left: 20px; font-size: 9pt; font-style: italic;\">Note: *** p<.001, ** p<.01, * p<.05</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "pubtable9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:04:59.812433Z",
     "iopub.status.busy": "2025-10-16T17:04:59.811886Z",
     "iopub.status.idle": "2025-10-16T17:04:59.818791Z",
     "shell.execute_reply": "2025-10-16T17:04:59.818249Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:48.544685Z",
     "start_time": "2025-10-16T22:49:48.539142Z"
    }
   },
   "source": [
    "# Test 8: Regression Table with Confidence Intervals\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 8: Regression Table with Confidence Intervals\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "html8 = regression_table(\n",
    "    models=model_pub.get_tidy(),\n",
    "    title='OLS Regression with Confidence Intervals',\n",
    "    show_se=False,\n",
    "    show_ci=True,\n",
    "    show_stars=True,\n",
    "    var_labels={'age': 'Age', 'income': 'Income', 'const': 'Intercept'}\n",
    ")\n",
    "\n",
    "display(HTML(html8))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 8: Regression Table with Confidence Intervals\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <style>\n",
       "        .pubtable {\n",
       "            font-family: 'Times New Roman', Times, serif;\n",
       "            border-collapse: collapse;\n",
       "            margin: 20px auto;\n",
       "            font-size: 11pt;\n",
       "            width: auto;\n",
       "            max-width: 100%;\n",
       "        }\n",
       "        .pubtable th {\n",
       "            border-top: 2px solid #000;\n",
       "            border-bottom: 1px solid #000;\n",
       "            padding: 8px 12px;\n",
       "            text-align: left;\n",
       "            font-weight: bold;\n",
       "        }\n",
       "        .pubtable td {\n",
       "            padding: 6px 12px;\n",
       "            text-align: left;\n",
       "        }\n",
       "        .pubtable tbody tr:last-child td {\n",
       "            border-bottom: 2px solid #000;\n",
       "        }\n",
       "        .pubtable .number {\n",
       "            text-align: right;\n",
       "            font-feature-settings: 'tnum';\n",
       "        }\n",
       "        .pubtable caption {\n",
       "            caption-side: top;\n",
       "            text-align: left;\n",
       "            font-weight: bold;\n",
       "            padding-bottom: 10px;\n",
       "            font-size: 12pt;\n",
       "        }\n",
       "        .pubtable .note {\n",
       "            font-size: 9pt;\n",
       "            font-style: italic;\n",
       "            padding-top: 5px;\n",
       "            border-top: none;\n",
       "        }\n",
       "        .pubtable .indent {\n",
       "            padding-left: 24px;\n",
       "        }\n",
       "    </style>\n",
       "    <table class=\"pubtable\"><caption>OLS Regression with Confidence Intervals</caption><thead><tr><th class=\"\"></th><th class=\"number\">Model 1</th></tr></thead><tbody><tr><td class=\"\">Intercept</td><td class=\"number\">7.958***</td></tr><tr><td class=\" indent\"></td><td class=\"number\">[7.162, 8.754]</td></tr><tr><td class=\"\">Age</td><td class=\"number\">-0.009</td></tr><tr><td class=\" indent\"></td><td class=\"number\">[-0.025, 0.006]</td></tr><tr><td class=\"\">Income</td><td class=\"number\">-0.000*</td></tr><tr><td class=\" indent\"></td><td class=\"number\">[-0.000, -0.000]</td></tr></tbody></table><p class=\"note\" style=\"margin-left: 20px; font-size: 9pt; font-style: italic;\">Note: *** p<.001, ** p<.01, * p<.05</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "# Summary - All Tests Complete âœ…\n",
    "\n",
    "All analysis modules have been successfully tested!\n",
    "\n",
    "## Modules Tested\n",
    "\n",
    "### Core Analyses\n",
    "1. **Regression Module** (`regress.py`)\n",
    "   - âœ… OLS regression (weighted & unweighted)\n",
    "   - âœ… Logistic regression\n",
    "   - âœ… Poisson regression\n",
    "   - âœ… Model comparison\n",
    "   - âœ… Predictions & diagnostics (VIF)\n",
    "\n",
    "2. **Publication Tables Module** (`pubtable.py`)\n",
    "   - âœ… Proportion tables (one-way & cross-tabulation)\n",
    "   - âœ… Weighted proportion tables\n",
    "   - âœ… Descriptive statistics tables\n",
    "   - âœ… Grouped descriptive statistics\n",
    "   - âœ… Regression coefficient tables\n",
    "   - âœ… Confidence intervals & significance stars\n",
    "\n",
    "### New Modules (2025-10-16)\n",
    "3. **Descriptive Statistics Module** (`descriptive.py`)\n",
    "   - âœ… Correlation matrices (Pearson, Spearman, Kendall)\n",
    "   - âœ… Cross-tabulations with chi-square tests\n",
    "   - âœ… Effect sizes (CramÃ©r's V, phi)\n",
    "   - âœ… Grouped summary statistics\n",
    "   - âœ… Group comparison tests (ANOVA, t-test)\n",
    "   - âœ… Distribution tests for normality\n",
    "\n",
    "4. **Causal Inference Module** (`causal.py`)\n",
    "   - âœ… Propensity score analysis (IPW, matching, regression adjustment)\n",
    "   - âœ… Balance checking for covariate balance\n",
    "   - âœ… Difference-in-differences (DiD) analysis\n",
    "   - âœ… Instrumental variables (2SLS) regression\n",
    "   - âœ… Regression discontinuity design (RDD)\n",
    "\n",
    "5. **Panel Data Module** (`panel.py`)\n",
    "   - âœ… Fixed effects (within) estimation\n",
    "   - âœ… Random effects (GLS) estimation\n",
    "   - âœ… First-difference estimation\n",
    "   - âœ… Hausman specification test\n",
    "   - âœ… Panel descriptive statistics\n",
    "\n",
    "6. **Machine Learning Module** (`ml.py`)\n",
    "   - âœ… Automated preprocessing pipelines\n",
    "   - âœ… Random Forest (classification & regression)\n",
    "   - âœ… Cross-validation\n",
    "   - âœ… Feature importance extraction\n",
    "   - âœ… Performance metrics\n",
    "\n",
    "### Data Handling\n",
    "7. **.dta Files with Categorical Variables**\n",
    "   - âœ… Loading with `load_stata()`\n",
    "   - âœ… Ordered categorical preservation\n",
    "   - âœ… Unordered categorical handling\n",
    "   - âœ… Variable labels preservation\n",
    "   - âœ… Integration with all analysis modules\n",
    "\n",
    "## Quick Navigation\n",
    "Use the table of contents at the top to jump to any section!\n",
    "\n",
    "## Dependencies Status\n",
    "- âœ… **Required**: pandas, numpy, statsmodels\n",
    "- âœ… **Recommended**: scipy (for descriptive stats)\n",
    "- âœ… **Optional**: sklearn (for ML), linearmodels (for enhanced panel features)\n",
    "\n",
    "---\n",
    "**Package**: sociopathit  \n",
    "**Test Date**: 2025-10-16  \n",
    "**Status**: All modules functional and tested"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vk2e46urr48",
   "metadata": {},
   "source": [
    "<a id='descriptive'></a>\n",
    "# 4. Descriptive Statistics\n",
    "\n",
    "Correlation matrices, crosstabs, grouped summaries with the `descriptive` module."
   ]
  },
  {
   "cell_type": "code",
   "id": "drwtfqxwawh",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:04:59.821123Z",
     "iopub.status.busy": "2025-10-16T17:04:59.820730Z",
     "iopub.status.idle": "2025-10-16T17:04:59.829362Z",
     "shell.execute_reply": "2025-10-16T17:04:59.828841Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:48.596116Z",
     "start_time": "2025-10-16T22:49:48.589307Z"
    }
   },
   "source": [
    "import importlib\n",
    "from sociopathit.analyses import descriptive as desc_module\n",
    "\n",
    "importlib.reload(desc_module)\n",
    "from sociopathit.analyses.descriptive import (\n",
    "    correlation_matrix, crosstab, group_summary, \n",
    "    distribution_test, describe_by_group, compare_groups\n",
    ")\n",
    "\n",
    "# Generate test data\n",
    "np.random.seed(42)\n",
    "n = 250\n",
    "df_desc = pd.DataFrame({\n",
    "    'age': np.random.normal(40, 12, n),\n",
    "    'income': np.random.normal(55000, 15000, n),\n",
    "    'education': np.random.normal(14, 2, n),\n",
    "    'satisfaction': np.random.normal(7, 1.5, n),\n",
    "    'region': np.random.choice(['North', 'South', 'East', 'West'], n),\n",
    "    'gender': np.random.choice(['Male', 'Female'], n),\n",
    "    'employed': np.random.choice(['Yes', 'No'], n, p=[0.7, 0.3]),\n",
    "    'weight': np.random.uniform(0.8, 1.2, n)\n",
    "})\n",
    "\n",
    "# Add some correlation\n",
    "df_desc['income'] = df_desc['income'] + df_desc['education'] * 3000\n",
    "df_desc['satisfaction'] = df_desc['satisfaction'] + df_desc['income'] / 20000\n",
    "\n",
    "print(df_desc.head())\n",
    "print(f\"\\nData shape: {df_desc.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         age         income  education  satisfaction region  gender employed  \\\n",
      "0  45.960570   83643.805970  15.852355      9.797340   East    Male       No   \n",
      "1  38.340828  122224.429049  17.818833     11.083695   West    Male      Yes   \n",
      "2  47.772262  120440.937512  11.202865     11.558237  North  Female      Yes   \n",
      "3  58.276358  115864.794328  15.125938     14.373702   West  Female      Yes   \n",
      "4  37.190160   70305.595096  12.698715      9.091181   East  Female       No   \n",
      "\n",
      "     weight  \n",
      "0  1.086529  \n",
      "1  0.828834  \n",
      "2  0.828503  \n",
      "3  0.804843  \n",
      "4  1.182601  \n",
      "\n",
      "Data shape: (250, 8)\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "aq51imoc0hr",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:04:59.831480Z",
     "iopub.status.busy": "2025-10-16T17:04:59.831152Z",
     "iopub.status.idle": "2025-10-16T17:04:59.842785Z",
     "shell.execute_reply": "2025-10-16T17:04:59.842312Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:48.648478Z",
     "start_time": "2025-10-16T22:49:48.637385Z"
    }
   },
   "source": [
    "# Test 1: Correlation Matrix\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 1: Correlation Matrix (Pearson)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "corr_mat, pval_mat = correlation_matrix(\n",
    "    df_desc, \n",
    "    variables=['age', 'income', 'education', 'satisfaction'],\n",
    "    method='pearson'\n",
    ")\n",
    "\n",
    "print(\"\\nCorrelation Matrix:\")\n",
    "print(corr_mat.round(3))\n",
    "print(\"\\nP-values:\")\n",
    "print(pval_mat.round(3))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 1: Correlation Matrix (Pearson)\n",
      "============================================================\n",
      "\n",
      "Correlation Matrix:\n",
      "                age  income  education  satisfaction\n",
      "age           1.000  -0.006      0.027         0.034\n",
      "income       -0.006   1.000      0.408         0.365\n",
      "education     0.027   0.408      1.000         0.170\n",
      "satisfaction  0.034   0.365      0.170         1.000\n",
      "\n",
      "P-values:\n",
      "                age  income  education  satisfaction\n",
      "age           0.000   0.927      0.668         0.596\n",
      "income        0.927   0.000      0.000         0.000\n",
      "education     0.668   0.000      0.000         0.007\n",
      "satisfaction  0.596   0.000      0.007         0.000\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "un3rzx8lik",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:04:59.845451Z",
     "iopub.status.busy": "2025-10-16T17:04:59.845268Z",
     "iopub.status.idle": "2025-10-16T17:04:59.854135Z",
     "shell.execute_reply": "2025-10-16T17:04:59.853325Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:48.699234Z",
     "start_time": "2025-10-16T22:49:48.690913Z"
    }
   },
   "source": [
    "# Test 2: Crosstab with Chi-Square\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 2: Crosstab with Chi-Square Test\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "crosstab_result = crosstab(\n",
    "    df_desc,\n",
    "    row_var='gender',\n",
    "    col_var='employed',\n",
    "    show_chi2=True,\n",
    "    show_effect_size=True\n",
    ")\n",
    "\n",
    "print(\"\\nContingency Table:\")\n",
    "print(crosstab_result['table'])\n",
    "print(f\"\\nChi-square: {crosstab_result['chi2']:.3f}\")\n",
    "print(f\"P-value: {crosstab_result['p_value']:.3f}\")\n",
    "print(f\"CramÃ©r's V: {crosstab_result['cramers_v']:.3f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 2: Crosstab with Chi-Square Test\n",
      "============================================================\n",
      "\n",
      "Contingency Table:\n",
      "employed  No  Yes\n",
      "gender           \n",
      "Female    36   89\n",
      "Male      34   91\n",
      "\n",
      "Chi-square: 0.020\n",
      "P-value: 0.888\n",
      "CramÃ©r's V: 0.009\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "yhjgepq60qa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:04:59.856562Z",
     "iopub.status.busy": "2025-10-16T17:04:59.856119Z",
     "iopub.status.idle": "2025-10-16T17:04:59.867284Z",
     "shell.execute_reply": "2025-10-16T17:04:59.865772Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:48.749401Z",
     "start_time": "2025-10-16T22:49:48.739055Z"
    }
   },
   "source": [
    "# Test 3: Group Summary\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 3: Grouped Descriptive Statistics\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "group_stats = group_summary(\n",
    "    df_desc,\n",
    "    variables=['income', 'satisfaction'],\n",
    "    group_var='region',\n",
    "    stats=['count', 'mean', 'std']\n",
    ")\n",
    "\n",
    "print(\"\\nGrouped Statistics by Region:\")\n",
    "print(group_stats)\n",
    "\n",
    "# Test 4: Compare Groups\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TEST 4: Compare Groups (ANOVA)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "comparison = compare_groups(df_desc, 'income', 'region', test='anova')\n",
    "print(f\"\\nTest: {comparison['test']}\")\n",
    "print(f\"Statistic: {comparison['statistic']:.3f}\")\n",
    "print(f\"P-value: {comparison['p_value']:.3f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 3: Grouped Descriptive Statistics\n",
      "============================================================\n",
      "\n",
      "Grouped Statistics by Region:\n",
      "  region  income_count   income_mean    income_std  satisfaction_count  \\\n",
      "0   East            62  97312.505805  15427.685956                  62   \n",
      "1  North            62  97465.056178  14765.904839                  62   \n",
      "2  South            61  98012.944346  16248.920807                  61   \n",
      "3   West            65  94682.561924  18839.202779                  65   \n",
      "\n",
      "   satisfaction_mean  satisfaction_std  \n",
      "0          12.015529          1.697530  \n",
      "1          11.948252          1.400435  \n",
      "2          12.151954          1.393657  \n",
      "3          12.039471          1.580121  \n",
      "\n",
      "============================================================\n",
      "TEST 4: Compare Groups (ANOVA)\n",
      "============================================================\n",
      "\n",
      "Test: One-way ANOVA\n",
      "Statistic: 0.524\n",
      "P-value: 0.666\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "26jbie6g6od",
   "metadata": {},
   "source": [
    "<a id='causal'></a>\n",
    "# 5. Causal Inference\n",
    "\n",
    "Propensity scores, DiD, IV regression with the `causal` module."
   ]
  },
  {
   "cell_type": "code",
   "id": "93lail5w81a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:04:59.869638Z",
     "iopub.status.busy": "2025-10-16T17:04:59.869462Z",
     "iopub.status.idle": "2025-10-16T17:04:59.878334Z",
     "shell.execute_reply": "2025-10-16T17:04:59.877825Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:48.806042Z",
     "start_time": "2025-10-16T22:49:48.797855Z"
    }
   },
   "source": [
    "import importlib\n",
    "from sociopathit.analyses import causal as causal_module\n",
    "\n",
    "importlib.reload(causal_module)\n",
    "from sociopathit.analyses.causal import (\n",
    "    propensity_score, difference_in_differences, \n",
    "    instrumental_variables, regression_discontinuity\n",
    ")\n",
    "\n",
    "# Generate causal inference test data\n",
    "np.random.seed(42)\n",
    "n = 400\n",
    "\n",
    "# Propensity score data\n",
    "df_ps = pd.DataFrame({\n",
    "    'age': np.random.normal(45, 10, n),\n",
    "    'income': np.random.normal(50000, 15000, n),\n",
    "    'education': np.random.normal(14, 2, n),\n",
    "})\n",
    "\n",
    "# Treatment assignment based on covariates (selection bias)\n",
    "ps_true = 1 / (1 + np.exp(-(\n",
    "    -2 + 0.03*df_ps['age'] + 0.00002*df_ps['income'] + 0.2*df_ps['education']\n",
    ")))\n",
    "df_ps['treated'] = (np.random.random(n) < ps_true).astype(int)\n",
    "\n",
    "# Outcome with treatment effect\n",
    "treatment_effect = 5.0\n",
    "df_ps['outcome'] = (\n",
    "    50 + \n",
    "    0.5*df_ps['age'] + \n",
    "    0.0001*df_ps['income'] + \n",
    "    2*df_ps['education'] +\n",
    "    treatment_effect*df_ps['treated'] +\n",
    "    np.random.normal(0, 5, n)\n",
    ")\n",
    "\n",
    "print(\"Propensity Score Data:\")\n",
    "print(df_ps.head())\n",
    "print(f\"Treatment rate: {df_ps['treated'].mean():.2%}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Propensity Score Data:\n",
      "         age        income  education  treated     outcome\n",
      "0  49.967142  26083.585118  15.876568        1  110.760953\n",
      "1  43.617357  41009.374656  12.967911        1   97.512754\n",
      "2  51.476885  50078.655496  14.192242        1  113.717388\n",
      "3  60.230299  50704.708906  13.075449        1  115.727781\n",
      "4  42.658466  43249.017928  13.131008        1  114.483399\n",
      "Treatment rate: 96.25%\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "wdz4mhoz7z",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:04:59.880587Z",
     "iopub.status.busy": "2025-10-16T17:04:59.880379Z",
     "iopub.status.idle": "2025-10-16T17:04:59.895866Z",
     "shell.execute_reply": "2025-10-16T17:04:59.895223Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:48.887931Z",
     "start_time": "2025-10-16T22:49:48.877150Z"
    }
   },
   "source": [
    "# Test 1: Propensity Score Analysis with IPW\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 1: Propensity Score Analysis (IPW)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "ps_model = propensity_score(\n",
    "    df_ps,\n",
    "    treatment='treated',\n",
    "    covariates=['age', 'income', 'education'],\n",
    "    outcome='outcome'\n",
    ")\n",
    "\n",
    "print(\"\\nPropensity scores (first 10):\")\n",
    "print(ps_model.propensity_scores.head(10))\n",
    "\n",
    "# Estimate ATE\n",
    "ate_result = ps_model.estimate_ate(method='ipw')\n",
    "print(f\"\\nAverage Treatment Effect (IPW):\")\n",
    "print(f\"  ATE: {ate_result['ate']:.3f}\")\n",
    "print(f\"  SE: {ate_result['se']:.3f}\")\n",
    "print(f\"  95% CI: [{ate_result['ci_lower']:.3f}, {ate_result['ci_upper']:.3f}]\")\n",
    "print(f\"  P-value: {ate_result['p_value']:.3f}\")\n",
    "print(f\"\\nTrue treatment effect: {treatment_effect:.3f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 1: Propensity Score Analysis (IPW)\n",
      "============================================================\n",
      "\n",
      "Propensity scores (first 10):\n",
      "0    0.955312\n",
      "1    0.977163\n",
      "2    0.956110\n",
      "3    0.942455\n",
      "4    0.977343\n",
      "5    0.973621\n",
      "6    0.935026\n",
      "7    0.961538\n",
      "8    0.963857\n",
      "9    0.967703\n",
      "dtype: float64\n",
      "\n",
      "Average Treatment Effect (IPW):\n",
      "  ATE: 5.249\n",
      "  SE: 1.860\n",
      "  95% CI: [1.604, 8.894]\n",
      "  P-value: 0.005\n",
      "\n",
      "True treatment effect: 5.000\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "xtuef222ra",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:04:59.898632Z",
     "iopub.status.busy": "2025-10-16T17:04:59.898301Z",
     "iopub.status.idle": "2025-10-16T17:04:59.911531Z",
     "shell.execute_reply": "2025-10-16T17:04:59.910980Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:48.973650Z",
     "start_time": "2025-10-16T22:49:48.964999Z"
    }
   },
   "source": [
    "# Test 2: Difference-in-Differences\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 2: Difference-in-Differences\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Generate DiD data\n",
    "np.random.seed(42)\n",
    "n_units = 100\n",
    "df_did = pd.DataFrame({\n",
    "    'unit': np.repeat(range(n_units), 2),\n",
    "    'time': np.tile([0, 1], n_units),\n",
    "    'treated': np.repeat([0]*50 + [1]*50, 2),\n",
    "})\n",
    "\n",
    "# Outcome: parallel trends with DiD effect\n",
    "did_effect = 8.0\n",
    "df_did['outcome'] = (\n",
    "    20 + \n",
    "    5*df_did['treated'] +  # Group difference\n",
    "    3*df_did['time'] +  # Time trend\n",
    "    did_effect*df_did['treated']*df_did['time'] +  # DiD effect\n",
    "    np.random.normal(0, 2, len(df_did))\n",
    ")\n",
    "\n",
    "did_result = difference_in_differences(\n",
    "    df_did,\n",
    "    outcome='outcome',\n",
    "    treatment='treated',\n",
    "    time='time',\n",
    "    unit='unit'\n",
    ")\n",
    "\n",
    "print(f\"\\nDiD Estimate: {did_result['did_estimate']:.3f}\")\n",
    "print(f\"SE: {did_result['se']:.3f}\")\n",
    "print(f\"P-value: {did_result['p_value']:.3f}\")\n",
    "print(f\"95% CI: [{did_result['ci_lower']:.3f}, {did_result['ci_upper']:.3f}]\")\n",
    "print(f\"\\nTrue DiD effect: {did_effect:.3f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 2: Difference-in-Differences\n",
      "============================================================\n",
      "\n",
      "DiD Estimate: 8.344\n",
      "SE: 0.527\n",
      "P-value: 0.000\n",
      "95% CI: [7.311, 9.377]\n",
      "\n",
      "True DiD effect: 8.000\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "id": "eb7uq71p6p",
   "source": "<a id='sem'></a>\n# 5. Structural Equation Modeling (SEM)\n\nTest path analysis and mediation models.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "x1zzz4ls39c",
   "source": "import importlib\nfrom sociopathit.analyses import sem as sem_module\nimportlib.reload(sem_module)\nfrom sociopathit.analyses.sem import PathModel, mediation, path_analysis\n\nprint(\"SEM module loaded successfully\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:49.036339Z",
     "start_time": "2025-10-16T22:49:49.032989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEM module loaded successfully\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "w1m81qxg4u",
   "source": "# Test 1: Simple Mediation Analysis\nprint(\"=\" * 60)\nprint(\"TEST 1: Simple Mediation Model\")\nprint(\"=\" * 60)\n\n# Simulate mediation data\nnp.random.seed(42)\nn = 300\ndf_mediation = pd.DataFrame({\n    'treatment': np.random.choice([0, 1], n),\n    'mediator': np.random.normal(50, 10, n),\n    'outcome': np.random.normal(100, 15, n),\n    'confounder': np.random.normal(0, 1, n)\n})\n\n# Create mediation structure\ndf_mediation['mediator'] = (\n    40 + 10 * df_mediation['treatment'] + \n    5 * df_mediation['confounder'] +\n    np.random.normal(0, 5, n)\n)\ndf_mediation['outcome'] = (\n    80 + 8 * df_mediation['mediator'] + \n    5 * df_mediation['treatment'] +\n    3 * df_mediation['confounder'] +\n    np.random.normal(0, 8, n)\n)\n\nprint(f\"\\nData shape: {df_mediation.shape}\")\nprint(f\"Treatment groups: {df_mediation['treatment'].value_counts().to_dict()}\")\n\n# Fit mediation model\nmodel_med = mediation(\n    df=df_mediation,\n    x='treatment',\n    m='mediator',\n    y='outcome',\n    standardize=True\n)\n\nprint(\"\\n\" + model_med.summary())\n\n# Calculate indirect effect\nindirect, se = model_med.indirect_effect(['treatment', 'mediator', 'outcome'])\nprint(f\"\\nIndirect Effect: {indirect:.4f} (SE = {se:.4f})\")\nprint(f\"Z-score: {indirect/se:.2f}\")\nprint(f\"Significant: {'Yes' if abs(indirect/se) > 1.96 else 'No'}\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:49.109429Z",
     "start_time": "2025-10-16T22:49:49.094582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 1: Simple Mediation Model\n",
      "============================================================\n",
      "\n",
      "Data shape: (300, 4)\n",
      "Treatment groups: {0: 151, 1: 149}\n",
      "\n",
      "Path Model Summary\n",
      "============================================================\n",
      "\n",
      "Model Fit:\n",
      "  N: 300\n",
      "  N_parameters: 5\n",
      "  Log-Likelihood: -130.586\n",
      "  AIC: 271.172\n",
      "  BIC: 289.691\n",
      "  R_squared_mediator: 0.406\n",
      "  R_squared_outcome: 0.986\n",
      "\n",
      "============================================================\n",
      "\n",
      "Path Coefficients:\n",
      "     from       to  estimate  std.error       p.value  standardized\n",
      "treatment mediator  0.637211   0.044645  1.406375e-35      0.637211\n",
      " mediator  outcome  0.984856   0.008869 6.742835e-244      0.984856\n",
      "treatment  outcome  0.012764   0.008869  1.511755e-01      0.012764\n",
      "\n",
      "Indirect Effect: 0.6276 (SE = 0.0443)\n",
      "Z-score: 14.16\n",
      "Significant: Yes\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "l0gbsdbmam",
   "source": "# Test 2: Complex Path Model\nprint(\"=\" * 60)\nprint(\"TEST 2: Multiple Mediator Path Analysis\")\nprint(\"=\" * 60)\n\n# Simulate complex path data\nnp.random.seed(42)\nn = 400\ndf_path = pd.DataFrame({\n    'X': np.random.normal(0, 1, n),\n    'M1': np.random.normal(0, 1, n),\n    'M2': np.random.normal(0, 1, n),\n    'Y': np.random.normal(0, 1, n)\n})\n\n# Create path structure: X -> M1 -> M2 -> Y\ndf_path['M1'] = 0.6 * df_path['X'] + np.random.normal(0, 0.8, n)\ndf_path['M2'] = 0.5 * df_path['M1'] + 0.3 * df_path['X'] + np.random.normal(0, 0.8, n)\ndf_path['Y'] = 0.4 * df_path['M2'] + 0.2 * df_path['M1'] + 0.1 * df_path['X'] + np.random.normal(0, 0.8, n)\n\n# Define path equations\nequations = {\n    'M1': ['X'],\n    'M2': ['M1', 'X'],\n    'Y': ['M2', 'M1', 'X']\n}\n\n# Fit path model\nmodel_path = PathModel(df_path, equations, standardize=True)\nmodel_path.fit()\n\nprint(\"\\n\" + model_path.summary())\n\n# Get path coefficients\npaths = model_path.get_paths()\nprint(\"\\nPath Coefficients Table:\")\nprint(paths.to_string(index=False))\n\n# Calculate indirect effects\nindirect_1 = model_path.indirect_effect(['X', 'M1', 'Y'])\nindirect_2 = model_path.indirect_effect(['X', 'M2', 'Y'])\nindirect_3 = model_path.indirect_effect(['X', 'M1', 'M2'])\n\nprint(f\"\\nIndirect Effects:\")\nprint(f\"  X -> M1 -> Y: {indirect_1[0]:.4f} (SE = {indirect_1[1]:.4f})\")\nprint(f\"  X -> M2 -> Y: {indirect_2[0]:.4f} (SE = {indirect_2[1]:.4f})\")\nprint(f\"  X -> M1 -> M2: {indirect_3[0]:.4f} (SE = {indirect_3[1]:.4f})\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:49.180381Z",
     "start_time": "2025-10-16T22:49:49.155544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 2: Multiple Mediator Path Analysis\n",
      "============================================================\n",
      "\n",
      "Path Model Summary\n",
      "============================================================\n",
      "\n",
      "Model Fit:\n",
      "  N: 400\n",
      "  N_parameters: 9\n",
      "  Log-Likelihood: -1398.709\n",
      "  AIC: 2815.419\n",
      "  BIC: 2851.342\n",
      "  R_squared_M1: 0.320\n",
      "  R_squared_M2: 0.447\n",
      "  R_squared_Y: 0.414\n",
      "\n",
      "============================================================\n",
      "\n",
      "Path Coefficients:\n",
      "from to  estimate  std.error      p.value  standardized\n",
      "   X M1  0.566083   0.041321 2.874724e-35      0.566083\n",
      "  M1 M2  0.467597   0.045292 2.716231e-22      0.467597\n",
      "   X M2  0.281190   0.045292 1.350078e-09      0.281190\n",
      "  M2  Y  0.456968   0.051705 3.225384e-17      0.456968\n",
      "  M1  Y  0.133183   0.052552 1.165154e-02      0.133183\n",
      "   X  Y  0.140754   0.048873 4.193093e-03      0.140754\n",
      "\n",
      "Path Coefficients Table:\n",
      "from to  estimate  std.error      p.value  standardized\n",
      "   X M1  0.566083   0.041321 2.874724e-35      0.566083\n",
      "  M1 M2  0.467597   0.045292 2.716231e-22      0.467597\n",
      "   X M2  0.281190   0.045292 1.350078e-09      0.281190\n",
      "  M2  Y  0.456968   0.051705 3.225384e-17      0.456968\n",
      "  M1  Y  0.133183   0.052552 1.165154e-02      0.133183\n",
      "   X  Y  0.140754   0.048873 4.193093e-03      0.140754\n",
      "\n",
      "Indirect Effects:\n",
      "  X -> M1 -> Y: 0.0754 (SE = 0.0303)\n",
      "  X -> M2 -> Y: 0.1285 (SE = 0.0253)\n",
      "  X -> M1 -> M2: 0.2647 (SE = 0.0321)\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "id": "7oljrmli039",
   "metadata": {},
   "source": [
    "<a id='panel'></a>\n",
    "# 6. Panel Data Models\n",
    "\n",
    "Fixed effects, random effects, first differences with the `panel` module."
   ]
  },
  {
   "cell_type": "code",
   "id": "5aix5txerlt",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:04:59.914843Z",
     "iopub.status.busy": "2025-10-16T17:04:59.914509Z",
     "iopub.status.idle": "2025-10-16T17:04:59.928271Z",
     "shell.execute_reply": "2025-10-16T17:04:59.927727Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:49.257756Z",
     "start_time": "2025-10-16T22:49:49.245586Z"
    }
   },
   "source": [
    "import importlib\n",
    "from sociopathit.analyses import panel as panel_module\n",
    "\n",
    "importlib.reload(panel_module)\n",
    "from sociopathit.analyses.panel import (\n",
    "    fixed_effects, random_effects, first_differences,\n",
    "    hausman_test, panel_summary\n",
    ")\n",
    "\n",
    "# Generate panel data\n",
    "np.random.seed(42)\n",
    "n_entities = 50\n",
    "n_time = 5\n",
    "\n",
    "df_panel = pd.DataFrame({\n",
    "    'entity': np.repeat(range(n_entities), n_time),\n",
    "    'time': np.tile(range(n_time), n_entities),\n",
    "})\n",
    "\n",
    "# Add entity fixed effects\n",
    "entity_effects = np.random.normal(0, 5, n_entities)\n",
    "df_panel['entity_effect'] = entity_effects[df_panel['entity']]\n",
    "\n",
    "# Add time-varying regressors\n",
    "df_panel['x1'] = np.random.normal(10, 2, len(df_panel))\n",
    "df_panel['x2'] = np.random.normal(5, 1, len(df_panel))\n",
    "\n",
    "# Outcome with fixed effects\n",
    "df_panel['y'] = (\n",
    "    df_panel['entity_effect'] +\n",
    "    2*df_panel['x1'] +\n",
    "    -1*df_panel['x2'] +\n",
    "    np.random.normal(0, 1, len(df_panel))\n",
    ")\n",
    "\n",
    "print(\"Panel Data:\")\n",
    "print(df_panel.head(10))\n",
    "print(f\"\\nData shape: {df_panel.shape}\")\n",
    "print(f\"Entities: {df_panel['entity'].nunique()}, Time periods: {df_panel['time'].nunique()}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Panel Data:\n",
      "   entity  time  entity_effect         x1        x2          y\n",
      "0       0     0       2.483571  10.648168  4.171005  19.695491\n",
      "1       0     1       2.483571   9.229835  4.439819  16.347745\n",
      "2       0     2       2.483571   8.646156  5.747294  15.196371\n",
      "3       0     3       2.483571  11.223353  5.610370  19.574326\n",
      "4       0     4       2.483571  12.061999  4.979098  21.966073\n",
      "5       1     0      -0.691322  11.862560  5.117327  17.504595\n",
      "6       1     1      -0.691322   8.321565  6.277665   9.186537\n",
      "7       1     2      -0.691322   9.381575  4.408429  13.230842\n",
      "8       1     3      -0.691322  10.662527  5.547097  15.481087\n",
      "9       1     4      -0.691322  11.951090  4.797807  17.992067\n",
      "\n",
      "Data shape: (250, 6)\n",
      "Entities: 50, Time periods: 5\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "id": "npeujglxdwf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:04:59.931224Z",
     "iopub.status.busy": "2025-10-16T17:04:59.930946Z",
     "iopub.status.idle": "2025-10-16T17:04:59.946349Z",
     "shell.execute_reply": "2025-10-16T17:04:59.945811Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:49.324626Z",
     "start_time": "2025-10-16T22:49:49.312874Z"
    }
   },
   "source": [
    "# Test 1: Fixed Effects Model\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 1: Fixed Effects (Within) Estimator\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "fe_result = fixed_effects(\n",
    "    df_panel,\n",
    "    outcome='y',\n",
    "    inputs=['x1', 'x2'],\n",
    "    entity='entity',\n",
    "    time='time'\n",
    ")\n",
    "\n",
    "print(\"\\nFixed Effects Coefficients:\")\n",
    "print(fe_result['coefficients'])\n",
    "print(\"\\nFit Statistics:\")\n",
    "for key, val in fe_result['fit_stats'].items():\n",
    "    if isinstance(val, float):\n",
    "        print(f\"  {key}: {val:.4f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {val}\")\n",
    "        \n",
    "print(\"\\nTrue coefficients: x1=2.0, x2=-1.0\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 1: Fixed Effects (Within) Estimator\n",
      "============================================================\n",
      "\n",
      "Fixed Effects Coefficients:\n",
      "  variable  estimate  std.error     t_stat       p.value\n",
      "0       x1  2.003788   0.031433  63.747573  0.000000e+00\n",
      "1       x2 -0.942080   0.065169 -14.455985  2.298171e-47\n",
      "\n",
      "Fit Statistics:\n",
      "  N: 250\n",
      "  N_entities: 50\n",
      "  R_squared: 0.9500\n",
      "\n",
      "True coefficients: x1=2.0, x2=-1.0\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "id": "79taxr290co",
   "metadata": {},
   "source": [
    "<a id='ml'></a>\n",
    "# 7. Machine Learning\n",
    "\n",
    "Random Forest, feature importance, predictive modeling with the `ml` module."
   ]
  },
  {
   "cell_type": "code",
   "id": "xb81eewmwc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:04:59.948642Z",
     "iopub.status.busy": "2025-10-16T17:04:59.948376Z",
     "iopub.status.idle": "2025-10-16T17:04:59.962103Z",
     "shell.execute_reply": "2025-10-16T17:04:59.961313Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:49.398502Z",
     "start_time": "2025-10-16T22:49:49.387100Z"
    }
   },
   "source": [
    "import importlib\n",
    "from sociopathit.analyses import ml as ml_module\n",
    "\n",
    "importlib.reload(ml_module)\n",
    "from sociopathit.analyses.ml import train_model, MLModel, feature_importance\n",
    "\n",
    "# Generate ML test data\n",
    "np.random.seed(42)\n",
    "n = 500\n",
    "\n",
    "df_ml = pd.DataFrame({\n",
    "    'age': np.random.normal(40, 12, n),\n",
    "    'income': np.random.normal(55000, 15000, n),\n",
    "    'education': np.random.normal(14, 2, n),\n",
    "    'experience': np.random.normal(15, 8, n),\n",
    "    'region': np.random.choice(['North', 'South', 'East', 'West'], n),\n",
    "})\n",
    "\n",
    "# Classification target (employed)\n",
    "employment_prob = 1 / (1 + np.exp(-(\n",
    "    -5 +\n",
    "    0.05*df_ml['age'] +\n",
    "    0.00003*df_ml['income'] +\n",
    "    0.3*df_ml['education'] +\n",
    "    0.1*df_ml['experience']\n",
    ")))\n",
    "df_ml['employed'] = (np.random.random(n) < employment_prob).astype(int)\n",
    "\n",
    "# Regression target (salary)\n",
    "df_ml['salary'] = (\n",
    "    20000 +\n",
    "    500*df_ml['age'] +\n",
    "    0.5*df_ml['income'] +\n",
    "    3000*df_ml['education'] +\n",
    "    1000*df_ml['experience'] +\n",
    "    np.random.normal(0, 5000, n)\n",
    ")\n",
    "\n",
    "print(\"ML Test Data:\")\n",
    "print(df_ml.head())\n",
    "print(f\"\\nEmployment rate: {df_ml['employed'].mean():.2%}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML Test Data:\n",
      "         age        income  education  experience region  employed  \\\n",
      "0  45.960570  68892.663213  16.798711   21.226889  South         1   \n",
      "1  38.340828  83641.249607  15.849267   10.590514   East         1   \n",
      "2  47.772262  34021.486393  14.119261    8.454409  South         1   \n",
      "3  58.276358  63444.538550  12.706126   14.973004   East         1   \n",
      "4  37.190160  45240.361463  15.396447   13.638523   East         1   \n",
      "\n",
      "          salary  \n",
      "0  155050.032536  \n",
      "1  136669.843126  \n",
      "2  102326.302047  \n",
      "3  137050.389318  \n",
      "4  117866.311441  \n",
      "\n",
      "Employment rate: 99.20%\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "id": "1dr76comhvi",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:04:59.964738Z",
     "iopub.status.busy": "2025-10-16T17:04:59.964560Z",
     "iopub.status.idle": "2025-10-16T17:05:00.843892Z",
     "shell.execute_reply": "2025-10-16T17:05:00.842872Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:50.080882Z",
     "start_time": "2025-10-16T22:49:49.454005Z"
    }
   },
   "source": [
    "# Test 1: Classification Model\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 1: Random Forest Classification\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "ml_clf = train_model(\n",
    "    df_ml,\n",
    "    outcome='employed',\n",
    "    features=['age', 'income', 'education', 'experience', 'region'],\n",
    "    model_type='random_forest',\n",
    "    task='classification',\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(ml_clf.summary())\n",
    "\n",
    "# Feature importance\n",
    "feat_imp = ml_clf.get_feature_importance()\n",
    "print(\"\\nTop 5 Most Important Features:\")\n",
    "print(feat_imp.head())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 1: Random Forest Classification\n",
      "============================================================\n",
      "ML Model Summary\n",
      "============================================================\n",
      "\n",
      "Task: classification\n",
      "Outcome: employed\n",
      "Features: 5\n",
      "Train size: 400, Test size: 100\n",
      "\n",
      "Training Performance:\n",
      "  accuracy: 1.0000\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  auc: 1.0000\n",
      "\n",
      "Test Performance:\n",
      "  accuracy: 1.0000\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  auc: nan\n",
      "\n",
      "Cross-validation: 0.9900 (+/- 0.0050)\n",
      "\n",
      "\n",
      "Top 5 Most Important Features:\n",
      "       feature  importance\n",
      "0          age    0.319676\n",
      "3   experience    0.229493\n",
      "1       income    0.207631\n",
      "2    education    0.163464\n",
      "7  region_West    0.030101\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "id": "z5jfeyb0ra",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:05:00.847412Z",
     "iopub.status.busy": "2025-10-16T17:05:00.847063Z",
     "iopub.status.idle": "2025-10-16T17:05:02.222257Z",
     "shell.execute_reply": "2025-10-16T17:05:02.221338Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:51.024514Z",
     "start_time": "2025-10-16T22:49:50.122348Z"
    }
   },
   "source": [
    "# Test 2: Regression Model\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 2: Random Forest Regression\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "ml_reg = train_model(\n",
    "    df_ml,\n",
    "    outcome='salary',\n",
    "    features=['age', 'income', 'education', 'experience'],\n",
    "    model_type='random_forest',\n",
    "    task='regression',\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(ml_reg.summary())\n",
    "\n",
    "# Feature importance\n",
    "feat_imp_reg = ml_reg.get_feature_importance()\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(feat_imp_reg)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 2: Random Forest Regression\n",
      "============================================================\n",
      "ML Model Summary\n",
      "============================================================\n",
      "\n",
      "Task: regression\n",
      "Outcome: salary\n",
      "Features: 4\n",
      "Train size: 400, Test size: 100\n",
      "\n",
      "Training Performance:\n",
      "  r2: 0.9667\n",
      "  rmse: 2628.1120\n",
      "  mae: 2087.3531\n",
      "\n",
      "Test Performance:\n",
      "  r2: 0.7726\n",
      "  rmse: 7003.3384\n",
      "  mae: 5709.2503\n",
      "\n",
      "Cross-validation: 0.7453 (+/- 0.0135)\n",
      "\n",
      "\n",
      "Feature Importance:\n",
      "      feature  importance\n",
      "3  experience    0.339882\n",
      "1      income    0.320233\n",
      "0         age    0.188097\n",
      "2   education    0.151788\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "id": "c4b96qd6mni",
   "metadata": {},
   "source": [
    "<a id='stata'></a>\n",
    "# 8. Stata .dta Files with Categorical Variables\n",
    "\n",
    "Loading and working with .dta files that have ordered and unordered categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "n2ssk5xs3ol",
   "metadata": {},
   "source": [
    "### 8.1 Create and Load .dta File\n",
    "\n",
    "Create test data with ordered and unordered categorical variables, save as .dta, and reload."
   ]
  },
  {
   "cell_type": "code",
   "id": "bp0f9hpye8l",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:05:02.225474Z",
     "iopub.status.busy": "2025-10-16T17:05:02.225268Z",
     "iopub.status.idle": "2025-10-16T17:05:02.257585Z",
     "shell.execute_reply": "2025-10-16T17:05:02.256911Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:51.092374Z",
     "start_time": "2025-10-16T22:49:51.054069Z"
    }
   },
   "source": [
    "import tempfile\n",
    "from pathlib import Path\n",
    "from sociopathit.data.loading import load_stata\n",
    "\n",
    "# Create test data with categorical variables\n",
    "print(\"=\" * 60)\n",
    "print(\"Creating test .dta file with categorical variables\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "np.random.seed(42)\n",
    "n = 300\n",
    "\n",
    "# Create dataframe with various categorical types\n",
    "df_stata = pd.DataFrame({\n",
    "    'id': range(1, n+1),\n",
    "    'age': np.random.normal(45, 12, n),\n",
    "    'income': np.random.normal(60000, 20000, n),\n",
    "    # Ordered categorical: education level\n",
    "    'education': np.random.choice(['Less than HS', 'High School', 'Some College', 'Bachelor', 'Graduate'], n),\n",
    "    # Unordered categorical: region\n",
    "    'region': np.random.choice(['Northeast', 'Southeast', 'Midwest', 'Southwest', 'West'], n),\n",
    "    # Binary categorical: gender\n",
    "    'gender': np.random.choice(['Male', 'Female'], n),\n",
    "    # Ordered categorical: satisfaction\n",
    "    'satisfaction': np.random.choice(['Very Dissatisfied', 'Dissatisfied', 'Neutral', 'Satisfied', 'Very Satisfied'], n),\n",
    "    # Numeric outcome (will be overwritten)\n",
    "    'outcome': np.random.normal(100, 15, n),\n",
    "})\n",
    "\n",
    "# Convert to categorical with proper ordering\n",
    "education_order = ['Less than HS', 'High School', 'Some College', 'Bachelor', 'Graduate']\n",
    "satisfaction_order = ['Very Dissatisfied', 'Dissatisfied', 'Neutral', 'Satisfied', 'Very Satisfied']\n",
    "\n",
    "df_stata['education'] = pd.Categorical(df_stata['education'], categories=education_order, ordered=True)\n",
    "df_stata['satisfaction'] = pd.Categorical(df_stata['satisfaction'], categories=satisfaction_order, ordered=True)\n",
    "df_stata['region'] = pd.Categorical(df_stata['region'], ordered=False)\n",
    "df_stata['gender'] = pd.Categorical(df_stata['gender'], ordered=False)\n",
    "\n",
    "# Add some relationship to outcome based on education (use .cat.codes for numeric conversion)\n",
    "df_stata['outcome'] = (\n",
    "    80 + \n",
    "    10 * df_stata['education'].cat.codes +  # Uses 0-4 for education levels\n",
    "    0.0003 * df_stata['income'] +\n",
    "    0.2 * df_stata['age'] +\n",
    "    np.random.normal(0, 10, n)\n",
    ")\n",
    "\n",
    "# Create temporary directory for test file\n",
    "temp_dir = Path(tempfile.gettempdir()) / 'sociopathit_tests'\n",
    "temp_dir.mkdir(exist_ok=True)\n",
    "dta_path = temp_dir / 'test_survey.dta'\n",
    "\n",
    "# Save as Stata file\n",
    "try:\n",
    "    df_stata.to_stata(dta_path, write_index=False, version=118)\n",
    "    print(f\"\\nSaved test .dta file to: {dta_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nError saving .dta file: {e}\")\n",
    "    print(\"This is expected if you don't have write permissions to temp directory.\")\n",
    "    # Create in current directory as fallback\n",
    "    dta_path = Path('.') / 'test_survey.dta'\n",
    "    df_stata.to_stata(dta_path, write_index=False, version=118)\n",
    "    print(f\"Saved to current directory instead: {dta_path}\")\n",
    "\n",
    "# Load the Stata file with categorical conversion\n",
    "df_loaded = load_stata(dta_path, convert_categoricals=True)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Loaded .dta file - checking categorical variables\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nDataFrame shape: {df_loaded.shape}\")\n",
    "print(f\"\\nCategorical columns:\")\n",
    "for col in df_loaded.select_dtypes(include='category').columns:\n",
    "    cat_info = df_loaded[col].dtype\n",
    "    print(f\"  {col}: ordered={cat_info.ordered}\")\n",
    "    print(f\"    Categories ({len(cat_info.categories)}): {list(cat_info.categories)[:3]}...\")\n",
    "\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df_loaded.head())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Creating test .dta file with categorical variables\n",
      "============================================================\n",
      "\n",
      "Saved test .dta file to: C:\\Users\\alecw\\AppData\\Local\\Temp\\sociopathit_tests\\test_survey.dta\n",
      "\n",
      "============================================================\n",
      "Loaded .dta file - checking categorical variables\n",
      "============================================================\n",
      "\n",
      "DataFrame shape: (300, 8)\n",
      "\n",
      "Categorical columns:\n",
      "  education: ordered=True\n",
      "    Categories (5): ['Less than HS', 'High School', 'Some College']...\n",
      "  region: ordered=True\n",
      "    Categories (5): ['Midwest', 'Northeast', 'Southeast']...\n",
      "  gender: ordered=True\n",
      "    Categories (2): ['Female', 'Male']...\n",
      "  satisfaction: ordered=True\n",
      "    Categories (5): ['Very Dissatisfied', 'Dissatisfied', 'Neutral']...\n",
      "\n",
      "First 5 rows:\n",
      "   id        age        income     education     region  gender  \\\n",
      "0   1  50.960570  43420.099782      Bachelor    Midwest    Male   \n",
      "1   2  43.340828  48796.379196      Bachelor  Southeast  Female   \n",
      "2   3  52.772262  74945.872102      Graduate  Northeast    Male   \n",
      "3   4  63.276358  72207.405309   High School       West    Male   \n",
      "4   5  42.190160  59581.968121  Some College  Southeast  Female   \n",
      "\n",
      "     satisfaction     outcome  \n",
      "0         Neutral  136.752973  \n",
      "1    Dissatisfied  134.522130  \n",
      "2  Very Satisfied  143.274461  \n",
      "3    Dissatisfied  115.392935  \n",
      "4       Satisfied  129.862847  \n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "id": "tbser637r8j",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:05:02.259868Z",
     "iopub.status.busy": "2025-10-16T17:05:02.259685Z",
     "iopub.status.idle": "2025-10-16T17:05:02.276946Z",
     "shell.execute_reply": "2025-10-16T17:05:02.276325Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:51.153267Z",
     "start_time": "2025-10-16T22:49:51.132214Z"
    }
   },
   "source": [
    "# Test 1: Crosstab with Categorical Variables from .dta\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 1: Crosstab with .dta Categorical Variables\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Import descriptive module\n",
    "from sociopathit.analyses.descriptive import crosstab, group_summary\n",
    "\n",
    "# Test crosstab with unordered categoricals\n",
    "result_crosstab = crosstab(\n",
    "    df_loaded,\n",
    "    row_var='gender',\n",
    "    col_var='region',\n",
    "    show_chi2=True,\n",
    "    show_effect_size=True\n",
    ")\n",
    "\n",
    "print(\"\\nGender x Region Crosstab:\")\n",
    "print(result_crosstab['table'])\n",
    "print(f\"\\nChi-square: {result_crosstab['chi2']:.3f}, p-value: {result_crosstab['p_value']:.3f}\")\n",
    "print(f\"CramÃ©r's V: {result_crosstab['cramers_v']:.3f}\")\n",
    "\n",
    "# Test with ordered categorical\n",
    "result_crosstab2 = crosstab(\n",
    "    df_loaded,\n",
    "    row_var='education',\n",
    "    col_var='satisfaction',\n",
    "    normalize='index',\n",
    "    show_chi2=True\n",
    ")\n",
    "\n",
    "print(\"\\n\\nEducation x Satisfaction Crosstab (row percentages):\")\n",
    "print(result_crosstab2['proportions'].round(3))\n",
    "print(f\"\\nChi-square: {result_crosstab2['chi2']:.3f}, p-value: {result_crosstab2['p_value']:.3f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 1: Crosstab with .dta Categorical Variables\n",
      "============================================================\n",
      "\n",
      "Gender x Region Crosstab:\n",
      "region  Midwest  Northeast  Southeast  Southwest  West\n",
      "gender                                                \n",
      "Female       28         36         39         26    34\n",
      "Male         36         20         23         25    33\n",
      "\n",
      "Chi-square: 7.538, p-value: 0.110\n",
      "CramÃ©r's V: 0.159\n",
      "\n",
      "\n",
      "Education x Satisfaction Crosstab (row percentages):\n",
      "satisfaction  Very Dissatisfied  Dissatisfied  Neutral  Satisfied  \\\n",
      "education                                                           \n",
      "Less than HS              0.200         0.231    0.138      0.215   \n",
      "High School               0.180         0.164    0.230      0.230   \n",
      "Some College              0.215         0.185    0.154      0.215   \n",
      "Bachelor                  0.208         0.226    0.132      0.245   \n",
      "Graduate                  0.232         0.304    0.161      0.107   \n",
      "\n",
      "satisfaction  Very Satisfied  \n",
      "education                     \n",
      "Less than HS           0.215  \n",
      "High School            0.197  \n",
      "Some College           0.231  \n",
      "Bachelor               0.189  \n",
      "Graduate               0.196  \n",
      "\n",
      "Chi-square: 9.372, p-value: 0.897\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "id": "o8l8t7zw79",
   "metadata": {},
   "source": [
    "### 8.2 Crosstabs with Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "id": "p3kfp6k79e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:05:02.280182Z",
     "iopub.status.busy": "2025-10-16T17:05:02.279694Z",
     "iopub.status.idle": "2025-10-16T17:05:02.294033Z",
     "shell.execute_reply": "2025-10-16T17:05:02.293431Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:51.212768Z",
     "start_time": "2025-10-16T22:49:51.198964Z"
    }
   },
   "source": [
    "# Test 2: Grouped Summary by Categorical Variables\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 2: Grouped Summary by Categorical (.dta)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Group by education level (ordered categorical)\n",
    "grouped_by_edu = group_summary(\n",
    "    df_loaded,\n",
    "    variables=['income', 'age', 'outcome'],\n",
    "    group_var='education',\n",
    "    stats=['count', 'mean', 'std']\n",
    ")\n",
    "\n",
    "print(\"\\nSummary Statistics by Education Level:\")\n",
    "print(grouped_by_edu.round(2))\n",
    "\n",
    "# Group by region (unordered categorical)\n",
    "grouped_by_region = group_summary(\n",
    "    df_loaded,\n",
    "    variables='outcome',\n",
    "    group_var='region',\n",
    "    stats=['count', 'mean', 'std', 'min', 'max']\n",
    ")\n",
    "\n",
    "print(\"\\n\\nOutcome by Region:\")\n",
    "print(grouped_by_region.round(2))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 2: Grouped Summary by Categorical (.dta)\n",
      "============================================================\n",
      "\n",
      "Summary Statistics by Education Level:\n",
      "      education  income_count  income_mean  income_std  age_count  age_mean  \\\n",
      "0  Less than HS            65     58725.30    19635.03         65     44.07   \n",
      "1   High School            61     57881.61    17954.95         61     48.34   \n",
      "2  Some College            65     64358.65    20994.47         65     44.01   \n",
      "3      Bachelor            53     59739.84    17938.75         53     45.07   \n",
      "4      Graduate            56     56671.67    18806.55         56     43.17   \n",
      "\n",
      "   age_std  outcome_count  outcome_mean  outcome_std  \n",
      "0    12.24             65        105.81         9.99  \n",
      "1    12.08             61        118.11        12.49  \n",
      "2    12.46             65        129.15        10.93  \n",
      "3    10.46             53        138.33        11.49  \n",
      "4    11.08             56        143.57        10.03  \n",
      "\n",
      "\n",
      "Outcome by Region:\n",
      "      region outcome                              \n",
      "               count    mean    std    min     max\n",
      "0    Midwest      64  131.08  17.66  92.92  169.20\n",
      "1  Northeast      56  123.61  15.42  86.98  158.65\n",
      "2  Southeast      62  125.75  17.02  89.44  166.80\n",
      "3  Southwest      51  125.15  18.45  84.76  162.04\n",
      "4       West      67  124.74  18.48  87.36  161.52\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "id": "93haa0492pw",
   "metadata": {},
   "source": [
    "### 8.3 Grouped Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "id": "ydebg6ee96p",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:05:02.296271Z",
     "iopub.status.busy": "2025-10-16T17:05:02.295798Z",
     "iopub.status.idle": "2025-10-16T17:05:02.313684Z",
     "shell.execute_reply": "2025-10-16T17:05:02.313170Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:51.301138Z",
     "start_time": "2025-10-16T22:49:51.286862Z"
    }
   },
   "source": [
    "# Test 3: Regression with Categorical Variables from .dta\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 3: OLS Regression with Categorical Predictors (.dta)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Prepare data: convert categorical to dummy variables for regression\n",
    "df_reg = df_loaded.copy()\n",
    "\n",
    "# Get numeric columns and categorical columns\n",
    "numeric_cols = df_reg.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if 'id' in numeric_cols:\n",
    "    numeric_cols.remove('id')\n",
    "\n",
    "# Convert categoricals to dummies\n",
    "cat_cols = df_reg.select_dtypes(include='category').columns.tolist()\n",
    "df_reg_dummies = pd.get_dummies(df_reg, columns=cat_cols, drop_first=True, dtype=int)\n",
    "\n",
    "print(f\"\\nOriginal columns: {len(df_loaded.columns)}\")\n",
    "print(f\"After dummy encoding: {len(df_reg_dummies.columns)}\")\n",
    "\n",
    "# Fit regression with categorical dummies\n",
    "predictor_cols = [col for col in df_reg_dummies.columns \n",
    "                  if col not in ['outcome', 'id']]\n",
    "\n",
    "from sociopathit.analyses.regress import ols\n",
    "\n",
    "model_cat = ols(\n",
    "    df_reg_dummies,\n",
    "    outcome='outcome',\n",
    "    inputs=predictor_cols,\n",
    "    robust=True\n",
    ")\n",
    "\n",
    "print(\"\\nRegression Results (with categorical dummies):\")\n",
    "results_tidy = model_cat.get_tidy()\n",
    "print(results_tidy[results_tidy['p.value'] < 0.05].round(4))\n",
    "\n",
    "stats = model_cat.get_stats()\n",
    "print(f\"\\nR-squared: {stats['R_squared']:.4f}\")\n",
    "print(f\"Adj R-squared: {stats['Adj_R_squared']:.4f}\")\n",
    "print(f\"N: {stats['N']}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 3: OLS Regression with Categorical Predictors (.dta)\n",
      "============================================================\n",
      "\n",
      "Original columns: 8\n",
      "After dummy encoding: 17\n",
      "\n",
      "Regression Results (with categorical dummies):\n",
      "                         term  estimate  std.error  statistic  p.value  \\\n",
      "0                       const   82.2721     3.5161    23.3990   0.0000   \n",
      "1                         age    0.2059     0.0553     3.7250   0.0002   \n",
      "2                      income    0.0002     0.0000     8.5545   0.0000   \n",
      "3       education_High School   11.7438     1.6665     7.0470   0.0000   \n",
      "4      education_Some College   21.9451     1.7440    12.5832   0.0000   \n",
      "5          education_Bachelor   32.1642     1.7392    18.4932   0.0000   \n",
      "6          education_Graduate   38.3324     1.6589    23.1069   0.0000   \n",
      "12  satisfaction_Dissatisfied    3.3896     1.6961     1.9984   0.0457   \n",
      "\n",
      "    conf.low  conf.high  \n",
      "0    75.3807    89.1634  \n",
      "1     0.0976     0.3143  \n",
      "2     0.0002     0.0003  \n",
      "3     8.4775    15.0101  \n",
      "4    18.5269    25.3632  \n",
      "5    28.7553    35.5730  \n",
      "6    35.0810    41.5839  \n",
      "12    0.0652     6.7139  \n",
      "\n",
      "R-squared: 0.7108\n",
      "Adj R-squared: 0.6955\n",
      "N: 300\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "id": "8aimolp90x",
   "metadata": {},
   "source": [
    "### 8.4 Regression with Categorical Dummies"
   ]
  },
  {
   "cell_type": "code",
   "id": "0ujnr8qd60qa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:05:02.315873Z",
     "iopub.status.busy": "2025-10-16T17:05:02.315684Z",
     "iopub.status.idle": "2025-10-16T17:05:02.828677Z",
     "shell.execute_reply": "2025-10-16T17:05:02.828063Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:51.712925Z",
     "start_time": "2025-10-16T22:49:51.370987Z"
    }
   },
   "source": [
    "# Test 4: Machine Learning with Categorical Variables from .dta\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 4: ML with Categorical Features (.dta)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ML automatically handles categoricals through pipeline\n",
    "from sociopathit.analyses.ml import train_model\n",
    "\n",
    "# Convert outcome to binary for classification\n",
    "df_ml_cat = df_loaded.copy()\n",
    "median_outcome = df_ml_cat['outcome'].median()\n",
    "df_ml_cat['high_outcome'] = (df_ml_cat['outcome'] > median_outcome).astype(int)\n",
    "\n",
    "# Convert categorical columns to string for sklearn compatibility\n",
    "cat_features = []\n",
    "for col in df_ml_cat.select_dtypes(include='category').columns:\n",
    "    df_ml_cat[col] = df_ml_cat[col].astype(str)\n",
    "    cat_features.append(col)\n",
    "\n",
    "numeric_features = ['age', 'income']\n",
    "\n",
    "print(f\"\\nCategorical features: {cat_features}\")\n",
    "print(f\"Numeric features: {numeric_features}\")\n",
    "\n",
    "# Train classification model\n",
    "ml_model_cat = train_model(\n",
    "    df_ml_cat,\n",
    "    outcome='high_outcome',\n",
    "    features=numeric_features + cat_features,\n",
    "    model_type='random_forest',\n",
    "    task='classification',\n",
    "    n_estimators=50,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\n\" + ml_model_cat.summary())\n",
    "\n",
    "# Get feature importance\n",
    "feat_imp_cat = ml_model_cat.get_feature_importance()\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(feat_imp_cat.head(10))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 4: ML with Categorical Features (.dta)\n",
      "============================================================\n",
      "\n",
      "Categorical features: ['education', 'region', 'gender', 'satisfaction']\n",
      "Numeric features: ['age', 'income']\n",
      "\n",
      "ML Model Summary\n",
      "============================================================\n",
      "\n",
      "Task: classification\n",
      "Outcome: high_outcome\n",
      "Features: 6\n",
      "Train size: 240, Test size: 60\n",
      "\n",
      "Training Performance:\n",
      "  accuracy: 1.0000\n",
      "  precision: 1.0000\n",
      "  recall: 1.0000\n",
      "  f1: 1.0000\n",
      "  auc: 1.0000\n",
      "\n",
      "Test Performance:\n",
      "  accuracy: 0.7833\n",
      "  precision: 0.7914\n",
      "  recall: 0.7833\n",
      "  f1: 0.7818\n",
      "  auc: 0.8800\n",
      "\n",
      "Cross-validation: 0.8250 (+/- 0.0583)\n",
      "\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "                   feature  importance\n",
      "1                   income    0.191933\n",
      "5   education_Less than HS    0.170321\n",
      "0                      age    0.139423\n",
      "3       education_Graduate    0.111710\n",
      "4    education_High School    0.076450\n",
      "2       education_Bachelor    0.061647\n",
      "6   education_Some College    0.031224\n",
      "15    satisfaction_Neutral    0.026503\n",
      "8         region_Northeast    0.024746\n",
      "12           gender_Female    0.022285\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "id": "9e4ejjt0li",
   "metadata": {},
   "source": [
    "### 8.5 Machine Learning with Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "id": "93jqvjoe8ht",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:05:02.830878Z",
     "iopub.status.busy": "2025-10-16T17:05:02.830649Z",
     "iopub.status.idle": "2025-10-16T17:05:02.855993Z",
     "shell.execute_reply": "2025-10-16T17:05:02.854699Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:52.362826Z",
     "start_time": "2025-10-16T22:49:52.337432Z"
    }
   },
   "source": [
    "# Test 5: Publication Tables with Categorical Variables from .dta\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 5: Publication Tables with Categorical Data (.dta)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "from sociopathit.analyses.pubtable import proportion_table, descriptive_table\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# Proportion table for ordered categorical\n",
    "html_prop = proportion_table(\n",
    "    df=df_loaded,\n",
    "    row_var='education',\n",
    "    col_var='satisfaction',\n",
    "    title='Education Level by Satisfaction (from .dta)',\n",
    "    decimals=1,\n",
    "    show_n=True\n",
    ")\n",
    "\n",
    "print(\"\\nEducation x Satisfaction Table:\")\n",
    "display(HTML(html_prop))\n",
    "\n",
    "# Descriptive table grouped by categorical\n",
    "html_desc = descriptive_table(\n",
    "    df=df_loaded,\n",
    "    variables=['age', 'income', 'outcome'],\n",
    "    group_var='region',\n",
    "    stats=['mean', 'sd', 'n'],\n",
    "    decimals=2,\n",
    "    title='Demographics by Region (from .dta)'\n",
    ")\n",
    "\n",
    "print(\"\\nDescriptive Statistics by Region:\")\n",
    "display(HTML(html_desc))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 5: Publication Tables with Categorical Data (.dta)\n",
      "============================================================\n",
      "\n",
      "Education x Satisfaction Table:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <style>\n",
       "        .pubtable {\n",
       "            font-family: 'Times New Roman', Times, serif;\n",
       "            border-collapse: collapse;\n",
       "            margin: 20px auto;\n",
       "            font-size: 11pt;\n",
       "            width: auto;\n",
       "            max-width: 100%;\n",
       "        }\n",
       "        .pubtable th {\n",
       "            border-top: 2px solid #000;\n",
       "            border-bottom: 1px solid #000;\n",
       "            padding: 8px 12px;\n",
       "            text-align: left;\n",
       "            font-weight: bold;\n",
       "        }\n",
       "        .pubtable td {\n",
       "            padding: 6px 12px;\n",
       "            text-align: left;\n",
       "        }\n",
       "        .pubtable tbody tr:last-child td {\n",
       "            border-bottom: 2px solid #000;\n",
       "        }\n",
       "        .pubtable .number {\n",
       "            text-align: right;\n",
       "            font-feature-settings: 'tnum';\n",
       "        }\n",
       "        .pubtable caption {\n",
       "            caption-side: top;\n",
       "            text-align: left;\n",
       "            font-weight: bold;\n",
       "            padding-bottom: 10px;\n",
       "            font-size: 12pt;\n",
       "        }\n",
       "        .pubtable .note {\n",
       "            font-size: 9pt;\n",
       "            font-style: italic;\n",
       "            padding-top: 5px;\n",
       "            border-top: none;\n",
       "        }\n",
       "        .pubtable .indent {\n",
       "            padding-left: 24px;\n",
       "        }\n",
       "    </style>\n",
       "    <table class=\"pubtable\"><caption>Education Level by Satisfaction (from .dta)</caption><thead><tr><th class=\"\">education</th><th class=\"number\">Very Dissatisfied</th><th class=\"number\">Dissatisfied</th><th class=\"number\">Neutral</th><th class=\"number\">Satisfied</th><th class=\"number\">Very Satisfied</th></tr></thead><tbody><tr><td class=\"\">Less than HS</td><td class=\"number\">21.0</td><td class=\"number\">22.7</td><td class=\"number\">18.4</td><td class=\"number\">23.0</td><td class=\"number\">22.6</td></tr><tr><td class=\"\">High School</td><td class=\"number\">17.7</td><td class=\"number\">15.2</td><td class=\"number\">28.6</td><td class=\"number\">23.0</td><td class=\"number\">19.4</td></tr><tr><td class=\"\">Some College</td><td class=\"number\">22.6</td><td class=\"number\">18.2</td><td class=\"number\">20.4</td><td class=\"number\">23.0</td><td class=\"number\">24.2</td></tr><tr><td class=\"\">Bachelor</td><td class=\"number\">17.7</td><td class=\"number\">18.2</td><td class=\"number\">14.3</td><td class=\"number\">21.3</td><td class=\"number\">16.1</td></tr><tr><td class=\"\">Graduate</td><td class=\"number\">21.0</td><td class=\"number\">25.8</td><td class=\"number\">18.4</td><td class=\"number\">9.8</td><td class=\"number\">17.7</td></tr></tbody></table><p class=\"note\" style=\"margin-left: 20px; font-size: 9pt; font-style: italic;\">Note: 95% confidence intervals shown.</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Descriptive Statistics by Region:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <style>\n",
       "        .pubtable {\n",
       "            font-family: 'Times New Roman', Times, serif;\n",
       "            border-collapse: collapse;\n",
       "            margin: 20px auto;\n",
       "            font-size: 11pt;\n",
       "            width: auto;\n",
       "            max-width: 100%;\n",
       "        }\n",
       "        .pubtable th {\n",
       "            border-top: 2px solid #000;\n",
       "            border-bottom: 1px solid #000;\n",
       "            padding: 8px 12px;\n",
       "            text-align: left;\n",
       "            font-weight: bold;\n",
       "        }\n",
       "        .pubtable td {\n",
       "            padding: 6px 12px;\n",
       "            text-align: left;\n",
       "        }\n",
       "        .pubtable tbody tr:last-child td {\n",
       "            border-bottom: 2px solid #000;\n",
       "        }\n",
       "        .pubtable .number {\n",
       "            text-align: right;\n",
       "            font-feature-settings: 'tnum';\n",
       "        }\n",
       "        .pubtable caption {\n",
       "            caption-side: top;\n",
       "            text-align: left;\n",
       "            font-weight: bold;\n",
       "            padding-bottom: 10px;\n",
       "            font-size: 12pt;\n",
       "        }\n",
       "        .pubtable .note {\n",
       "            font-size: 9pt;\n",
       "            font-style: italic;\n",
       "            padding-top: 5px;\n",
       "            border-top: none;\n",
       "        }\n",
       "        .pubtable .indent {\n",
       "            padding-left: 24px;\n",
       "        }\n",
       "    </style>\n",
       "    <table class=\"pubtable\"><caption>Demographics by Region (from .dta)</caption><thead><tr><th class=\"\">Variable</th><th class=\"\">Group</th><th class=\"number\">Mean</th><th class=\"number\">Sd</th><th class=\"number\">N</th></tr></thead><tbody><tr><td class=\"\">age</td><td class=\"\">Midwest</td><td class=\"number\">45.30</td><td class=\"number\">12.12</td><td class=\"number\">64</td></tr><tr><td class=\" indent\"></td><td class=\"\">Northeast</td><td class=\"number\">46.58</td><td class=\"number\">13.91</td><td class=\"number\">56</td></tr><tr><td class=\" indent\"></td><td class=\"\">Southeast</td><td class=\"number\">45.12</td><td class=\"number\">11.01</td><td class=\"number\">62</td></tr><tr><td class=\" indent\"></td><td class=\"\">Southwest</td><td class=\"number\">44.13</td><td class=\"number\">9.63</td><td class=\"number\">51</td></tr><tr><td class=\" indent\"></td><td class=\"\">West</td><td class=\"number\">43.65</td><td class=\"number\">11.54</td><td class=\"number\">67</td></tr><tr><td class=\"\">income</td><td class=\"\">Midwest</td><td class=\"number\">64999.19</td><td class=\"number\">22070.49</td><td class=\"number\">64</td></tr><tr><td class=\" indent\"></td><td class=\"\">Northeast</td><td class=\"number\">60136.71</td><td class=\"number\">19727.56</td><td class=\"number\">56</td></tr><tr><td class=\" indent\"></td><td class=\"\">Southeast</td><td class=\"number\">60134.96</td><td class=\"number\">15395.76</td><td class=\"number\">62</td></tr><tr><td class=\" indent\"></td><td class=\"\">Southwest</td><td class=\"number\">54361.41</td><td class=\"number\">21306.41</td><td class=\"number\">51</td></tr><tr><td class=\" indent\"></td><td class=\"\">West</td><td class=\"number\">57353.08</td><td class=\"number\">15521.47</td><td class=\"number\">67</td></tr><tr><td class=\"\">outcome</td><td class=\"\">Midwest</td><td class=\"number\">131.08</td><td class=\"number\">17.52</td><td class=\"number\">64</td></tr><tr><td class=\" indent\"></td><td class=\"\">Northeast</td><td class=\"number\">123.61</td><td class=\"number\">15.28</td><td class=\"number\">56</td></tr><tr><td class=\" indent\"></td><td class=\"\">Southeast</td><td class=\"number\">125.75</td><td class=\"number\">16.88</td><td class=\"number\">62</td></tr><tr><td class=\" indent\"></td><td class=\"\">Southwest</td><td class=\"number\">125.15</td><td class=\"number\">18.27</td><td class=\"number\">51</td></tr><tr><td class=\" indent\"></td><td class=\"\">West</td><td class=\"number\">124.74</td><td class=\"number\">18.34</td><td class=\"number\">67</td></tr></tbody></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "id": "yx6tp6hhrt",
   "metadata": {},
   "source": [
    "### 8.6 Publication Tables with Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ejsa0v7zhfe",
   "metadata": {},
   "source": [
    "<a id='textanalysis'></a>\n",
    "# 9. Text Analysis\n",
    "\n",
    "Text preprocessing, complexity metrics, similarity, topic modeling with the `text_analysis` module."
   ]
  },
  {
   "cell_type": "code",
   "id": "k27i4i4v9q",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:05:02.859008Z",
     "iopub.status.busy": "2025-10-16T17:05:02.858591Z",
     "iopub.status.idle": "2025-10-16T17:05:02.864665Z",
     "shell.execute_reply": "2025-10-16T17:05:02.864086Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:52.470217Z",
     "start_time": "2025-10-16T22:49:52.464773Z"
    }
   },
   "source": "import importlib\nfrom sociopathit.analyses import text_analysis as text_module\n\nimportlib.reload(text_module)\nfrom sociopathit.analyses.text_analysis import (\n    clean_text, tokenize, complexity_scores, \n    jaccard_similarity, create_tfidf_matrix, TopicModel,\n    extract_ngrams, ngram_frequency, analyze_corpus,\n    SentimentAnalyzer, BERTModel, OllamaClassifier,\n    HAS_TRANSFORMERS, HAS_REQUESTS, HAS_SKLEARN\n)\n\n# Create sample texts for testing\nsample_texts = [\n    \"The quick brown fox jumps over the lazy dog. This is a simple sentence for testing text analysis.\",\n    \"Natural language processing is an exciting field of study. It combines linguistics and computer science.\",\n    \"Machine learning algorithms can analyze large amounts of text data. They identify patterns and extract insights.\",\n    \"Text mining techniques help researchers discover hidden patterns. Statistical methods are commonly used.\",\n    \"Data science involves collecting, processing, and analyzing data. Python is a popular programming language for data analysis.\"\n]\n\nprint(\"Sample Texts Generated:\")\nprint(f\"Number of texts: {len(sample_texts)}\")\nprint(f\"\\nFirst text: {sample_texts[0][:100]}...\")\nprint(f\"\\nDependencies available:\")\nprint(f\"  - Transformers: {HAS_TRANSFORMERS}\")\nprint(f\"  - Requests (for Ollama): {HAS_REQUESTS}\")\nprint(f\"  - Scikit-learn: {HAS_SKLEARN}\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Texts Generated:\n",
      "Number of texts: 5\n",
      "\n",
      "First text: The quick brown fox jumps over the lazy dog. This is a simple sentence for testing text analysis....\n",
      "\n",
      "Dependencies available:\n",
      "  - Transformers: True\n",
      "  - Requests (for Ollama): True\n",
      "  - Scikit-learn: True\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "id": "87c469aybpc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:05:02.866837Z",
     "iopub.status.busy": "2025-10-16T17:05:02.866603Z",
     "iopub.status.idle": "2025-10-16T17:05:02.870651Z",
     "shell.execute_reply": "2025-10-16T17:05:02.870073Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:52.549506Z",
     "start_time": "2025-10-16T22:49:52.546319Z"
    }
   },
   "source": [
    "# Test 3: Text Similarity\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 3: Text Similarity\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "text1 = \"The cat sat on the mat\"\n",
    "text2 = \"The dog sat on the rug\"\n",
    "text3 = \"Machine learning is fascinating\"\n",
    "\n",
    "jac_sim_12 = jaccard_similarity(text1, text2)\n",
    "jac_sim_13 = jaccard_similarity(text1, text3)\n",
    "\n",
    "print(f\"\\nText 1: {text1}\")\n",
    "print(f\"Text 2: {text2}\")\n",
    "print(f\"Text 3: {text3}\")\n",
    "print(f\"\\nJaccard Similarity (Text 1 vs Text 2): {jac_sim_12:.3f}\")\n",
    "print(f\"Jaccard Similarity (Text 1 vs Text 3): {jac_sim_13:.3f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 3: Text Similarity\n",
      "============================================================\n",
      "\n",
      "Text 1: The cat sat on the mat\n",
      "Text 2: The dog sat on the rug\n",
      "Text 3: Machine learning is fascinating\n",
      "\n",
      "Jaccard Similarity (Text 1 vs Text 2): 0.429\n",
      "Jaccard Similarity (Text 1 vs Text 3): 0.000\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "id": "9uon7n9pb9u",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:05:02.873102Z",
     "iopub.status.busy": "2025-10-16T17:05:02.872705Z",
     "iopub.status.idle": "2025-10-16T17:05:02.879526Z",
     "shell.execute_reply": "2025-10-16T17:05:02.878872Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:52.622800Z",
     "start_time": "2025-10-16T22:49:52.617298Z"
    }
   },
   "source": [
    "# Test 6: N-gram Analysis\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 6: N-gram Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "text_for_ngrams = \"machine learning and data science are exciting fields of study\"\n",
    "\n",
    "# Extract bigrams\n",
    "bigrams = extract_ngrams(text_for_ngrams, n=2, top_k=5)\n",
    "print(f\"\\nText: {text_for_ngrams}\")\n",
    "print(f\"\\nTop 5 Bigrams:\")\n",
    "for ngram, count in bigrams:\n",
    "    print(f\"  {' '.join(ngram)}: {count}\")\n",
    "\n",
    "# N-gram frequency across multiple texts\n",
    "ngram_freq = ngram_frequency(sample_texts, n=2, top_k=10)\n",
    "print(f\"\\nTop 10 Bigrams Across All Texts:\")\n",
    "print(ngram_freq)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 6: N-gram Analysis\n",
      "============================================================\n",
      "\n",
      "Text: machine learning and data science are exciting fields of study\n",
      "\n",
      "Top 5 Bigrams:\n",
      "  machine learning: 1\n",
      "  learning and: 1\n",
      "  and data: 1\n",
      "  data science: 1\n",
      "  science are: 1\n",
      "\n",
      "Top 10 Bigrams Across All Texts:\n",
      "            ngram  frequency\n",
      "0         (is, a)          2\n",
      "1    (the, quick)          1\n",
      "2  (quick, brown)          1\n",
      "3    (brown, fox)          1\n",
      "4    (fox, jumps)          1\n",
      "5   (jumps, over)          1\n",
      "6     (over, the)          1\n",
      "7     (the, lazy)          1\n",
      "8     (lazy, dog)          1\n",
      "9     (dog, this)          1\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "id": "j6ywkl0v1fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:05:02.882022Z",
     "iopub.status.busy": "2025-10-16T17:05:02.881810Z",
     "iopub.status.idle": "2025-10-16T17:05:02.889062Z",
     "shell.execute_reply": "2025-10-16T17:05:02.888470Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:52.726484Z",
     "start_time": "2025-10-16T22:49:52.719971Z"
    }
   },
   "source": [
    "# Test 6: Correlation Network\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 6: Correlation Network\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "from sociopathit.analyses.network import correlation_network, network_summary\n",
    "\n",
    "# Use existing data\n",
    "corr_network = correlation_network(\n",
    "    df_desc,\n",
    "    variables=['age', 'income', 'education', 'satisfaction'],\n",
    "    method='pearson',\n",
    "    threshold=0.3,\n",
    "    absolute=False\n",
    ")\n",
    "\n",
    "print(\"\\nCorrelation Network (threshold=0.3):\")\n",
    "print(corr_network)\n",
    "\n",
    "# Summary\n",
    "if len(corr_network) > 0:\n",
    "    corr_stats = network_summary(corr_network, directed=False)\n",
    "    print(\"\\nNetwork Statistics:\")\n",
    "    for key, value in corr_stats.items():\n",
    "        print(f\"  {key}: {value}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 6: Correlation Network\n",
      "============================================================\n",
      "\n",
      "Correlation Network (threshold=0.3):\n",
      "   source        target    weight  correlation\n",
      "0  income     education  0.408189     0.408189\n",
      "1  income  satisfaction  0.364734     0.364734\n",
      "\n",
      "Network Statistics:\n",
      "  n_nodes: 3\n",
      "  n_edges: 2\n",
      "  density: 0.3333333333333333\n",
      "  avg_degree: 1.3333333333333333\n",
      "  max_degree: 2\n",
      "  min_degree: 1\n",
      "  total_weight: 0.7729233321616\n",
      "  avg_weight: 0.3864616660808\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "id": "0w7rbuzgttdk",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:05:02.891461Z",
     "iopub.status.busy": "2025-10-16T17:05:02.891231Z",
     "iopub.status.idle": "2025-10-16T17:05:02.901155Z",
     "shell.execute_reply": "2025-10-16T17:05:02.900363Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:52.838861Z",
     "start_time": "2025-10-16T22:49:52.830379Z"
    }
   },
   "source": [
    "# Test 5: Similarity-based Network\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 5: Similarity-based Network\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create feature data\n",
    "feature_data = pd.DataFrame({\n",
    "    'id': ['Item1', 'Item2', 'Item3', 'Item4'],\n",
    "    'feature1': [1.0, 2.0, 1.5, 3.0],\n",
    "    'feature2': [2.0, 3.0, 2.5, 4.0],\n",
    "    'feature3': [1.5, 1.0, 1.2, 2.0]\n",
    "})\n",
    "\n",
    "print(\"\\nFeature Data:\")\n",
    "print(feature_data)\n",
    "\n",
    "try:\n",
    "    from sociopathit.analyses.network import similarity_network\n",
    "    \n",
    "    sim_network = similarity_network(\n",
    "        feature_data,\n",
    "        features=['feature1', 'feature2', 'feature3'],\n",
    "        node_id_col='id',\n",
    "        similarity_metric='cosine',\n",
    "        threshold=0.9\n",
    "    )\n",
    "    \n",
    "    print(\"\\nSimilarity Network (cosine, threshold=0.9):\")\n",
    "    print(sim_network)\n",
    "except ImportError as e:\n",
    "    print(f\"\\nSkipping similarity network test: {e}\")\n",
    "    print(\"scikit-learn is required for this feature\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 5: Similarity-based Network\n",
      "============================================================\n",
      "\n",
      "Feature Data:\n",
      "      id  feature1  feature2  feature3\n",
      "0  Item1       1.0       2.0       1.5\n",
      "1  Item2       2.0       3.0       1.0\n",
      "2  Item3       1.5       2.5       1.2\n",
      "3  Item4       3.0       4.0       2.0\n",
      "\n",
      "Similarity Network (cosine, threshold=0.9):\n",
      "  source target    weight\n",
      "0  Item1  Item2  0.942954\n",
      "1  Item1  Item3  0.977723\n",
      "2  Item1  Item4  0.965517\n",
      "3  Item2  Item3  0.991810\n",
      "4  Item2  Item4  0.992583\n",
      "5  Item3  Item4  0.995393\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "id": "972snl0uihi",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:05:02.908022Z",
     "iopub.status.busy": "2025-10-16T17:05:02.907634Z",
     "iopub.status.idle": "2025-10-16T17:05:02.926131Z",
     "shell.execute_reply": "2025-10-16T17:05:02.925260Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:52.939227Z",
     "start_time": "2025-10-16T22:49:52.928439Z"
    }
   },
   "source": [
    "# Test 4: Bipartite Network\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 4: Bipartite Network and Projection\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "from sociopathit.analyses.network import create_bipartite_edgelist, project_bipartite\n",
    "\n",
    "# Create bipartite edge list (users and products)\n",
    "user_product = pd.DataFrame({\n",
    "    'user': ['User1', 'User1', 'User2', 'User2', 'User3', 'User3', 'User4'],\n",
    "    'product': ['ProductA', 'ProductB', 'ProductA', 'ProductC', 'ProductB', 'ProductC', 'ProductA'],\n",
    "    'rating': [5, 4, 3, 5, 4, 2, 5]\n",
    "})\n",
    "\n",
    "print(\"\\nUser-Product Data:\")\n",
    "print(user_product)\n",
    "\n",
    "bipartite_edges = create_bipartite_edgelist(\n",
    "    user_product,\n",
    "    node_type1_col='user',\n",
    "    node_type2_col='product',\n",
    "    weight_col='rating'\n",
    ")\n",
    "\n",
    "print(\"\\nBipartite Edge List:\")\n",
    "print(bipartite_edges)\n",
    "\n",
    "# Project onto users\n",
    "user_network = project_bipartite(bipartite_edges, project_on='type1', weight_method='simple')\n",
    "\n",
    "print(\"\\nUser-User Network (shared products):\")\n",
    "print(user_network)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 4: Bipartite Network and Projection\n",
      "============================================================\n",
      "\n",
      "User-Product Data:\n",
      "    user   product  rating\n",
      "0  User1  ProductA       5\n",
      "1  User1  ProductB       4\n",
      "2  User2  ProductA       3\n",
      "3  User2  ProductC       5\n",
      "4  User3  ProductB       4\n",
      "5  User3  ProductC       2\n",
      "6  User4  ProductA       5\n",
      "\n",
      "Bipartite Edge List:\n",
      "  type1_node type2_node  weight\n",
      "0      User1   ProductA       5\n",
      "1      User1   ProductB       4\n",
      "2      User2   ProductA       3\n",
      "3      User2   ProductC       5\n",
      "4      User3   ProductB       4\n",
      "5      User3   ProductC       2\n",
      "6      User4   ProductA       5\n",
      "\n",
      "User-User Network (shared products):\n",
      "  source target  weight  shared_neighbors\n",
      "0  User1  User2       1                 1\n",
      "1  User1  User3       1                 1\n",
      "2  User1  User4       1                 1\n",
      "3  User2  User3       1                 1\n",
      "4  User2  User4       1                 1\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "id": "ghe6axrcdym",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:05:02.929604Z",
     "iopub.status.busy": "2025-10-16T17:05:02.929230Z",
     "iopub.status.idle": "2025-10-16T17:05:02.943388Z",
     "shell.execute_reply": "2025-10-16T17:05:02.942839Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:53.020239Z",
     "start_time": "2025-10-16T22:49:53.012630Z"
    }
   },
   "source": [
    "# Test 3: Co-occurrence Network\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 3: Co-occurrence Network\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "from sociopathit.analyses.network import cooccurrence_network, network_summary\n",
    "\n",
    "# Create co-occurrence data (e.g., actors in movies)\n",
    "movies_data = pd.DataFrame({\n",
    "    'movie': ['Movie1', 'Movie1', 'Movie1', 'Movie2', 'Movie2', 'Movie3', 'Movie3', 'Movie3'],\n",
    "    'actor': ['Alice', 'Bob', 'Charlie', 'Alice', 'Bob', 'Bob', 'Charlie', 'David']\n",
    "})\n",
    "\n",
    "print(\"\\nMovies Data:\")\n",
    "print(movies_data)\n",
    "\n",
    "cooccur_net = cooccurrence_network(\n",
    "    movies_data,\n",
    "    item_col='actor',\n",
    "    group_col='movie',\n",
    "    min_cooccurrence=1\n",
    ")\n",
    "\n",
    "print(\"\\nCo-occurrence Network:\")\n",
    "print(cooccur_net)\n",
    "\n",
    "# Network summary\n",
    "net_stats = network_summary(cooccur_net, directed=False)\n",
    "print(\"\\nNetwork Statistics:\")\n",
    "for key, value in net_stats.items():\n",
    "    print(f\"  {key}: {value}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 3: Co-occurrence Network\n",
      "============================================================\n",
      "\n",
      "Movies Data:\n",
      "    movie    actor\n",
      "0  Movie1    Alice\n",
      "1  Movie1      Bob\n",
      "2  Movie1  Charlie\n",
      "3  Movie2    Alice\n",
      "4  Movie2      Bob\n",
      "5  Movie3      Bob\n",
      "6  Movie3  Charlie\n",
      "7  Movie3    David\n",
      "\n",
      "Co-occurrence Network:\n",
      "    source   target  weight  cooccurrence_count\n",
      "0      Bob  Charlie       2                   2\n",
      "1    Alice      Bob       2                   2\n",
      "2    Alice  Charlie       1                   1\n",
      "3      Bob    David       1                   1\n",
      "4  Charlie    David       1                   1\n",
      "\n",
      "Network Statistics:\n",
      "  n_nodes: 4\n",
      "  n_edges: 5\n",
      "  density: 0.4166666666666667\n",
      "  avg_degree: 2.5\n",
      "  max_degree: 3\n",
      "  min_degree: 2\n",
      "  total_weight: 7\n",
      "  avg_weight: 1.4\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "id": "100almoc69jb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:05:02.946710Z",
     "iopub.status.busy": "2025-10-16T17:05:02.946497Z",
     "iopub.status.idle": "2025-10-16T17:05:02.971309Z",
     "shell.execute_reply": "2025-10-16T17:05:02.970475Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:53.114535Z",
     "start_time": "2025-10-16T22:49:53.100458Z"
    }
   },
   "source": [
    "# Test 1 & 2: Create Edge List and Adjacency Matrix\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 1: Create Edge List from DataFrame\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create sample interaction data\n",
    "np.random.seed(42)\n",
    "interactions = pd.DataFrame({\n",
    "    'person_a': ['Alice', 'Bob', 'Alice', 'Charlie', 'Bob', 'Alice'],\n",
    "    'person_b': ['Bob', 'Charlie', 'Charlie', 'Alice', 'Alice', 'Bob'],\n",
    "    'strength': [5, 3, 2, 4, 6, 1]\n",
    "})\n",
    "\n",
    "print(\"\\nInteraction Data:\")\n",
    "print(interactions)\n",
    "\n",
    "# Ensure import\n",
    "from sociopathit.analyses.network import create_edgelist, create_adjacency_matrix, adjacency_to_edgelist\n",
    "\n",
    "# Create directed edge list\n",
    "edgelist_directed = create_edgelist(\n",
    "    interactions, \n",
    "    source_col='person_a',\n",
    "    target_col='person_b',\n",
    "    weight_col='strength',\n",
    "    directed=True\n",
    ")\n",
    "\n",
    "print(\"\\nDirected Edge List:\")\n",
    "print(edgelist_directed)\n",
    "\n",
    "# Create undirected edge list\n",
    "edgelist_undirected = create_edgelist(\n",
    "    interactions,\n",
    "    source_col='person_a',\n",
    "    target_col='person_b',\n",
    "    weight_col='strength',\n",
    "    directed=False\n",
    ")\n",
    "\n",
    "print(\"\\nUndirected Edge List:\")\n",
    "print(edgelist_undirected)\n",
    "\n",
    "# TEST 2: Adjacency Matrix\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TEST 2: Create Adjacency Matrix\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "adj_matrix = create_adjacency_matrix(edgelist_directed, weighted=True)\n",
    "\n",
    "print(\"\\nAdjacency Matrix (weighted):\")\n",
    "print(adj_matrix)\n",
    "\n",
    "# Convert back to edge list\n",
    "edgelist_from_adj = adjacency_to_edgelist(adj_matrix, directed=True)\n",
    "\n",
    "print(\"\\nEdge List from Adjacency Matrix:\")\n",
    "print(edgelist_from_adj)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 1: Create Edge List from DataFrame\n",
      "============================================================\n",
      "\n",
      "Interaction Data:\n",
      "  person_a person_b  strength\n",
      "0    Alice      Bob         5\n",
      "1      Bob  Charlie         3\n",
      "2    Alice  Charlie         2\n",
      "3  Charlie    Alice         4\n",
      "4      Bob    Alice         6\n",
      "5    Alice      Bob         1\n",
      "\n",
      "Directed Edge List:\n",
      "    source   target  weight\n",
      "0    Alice      Bob       6\n",
      "1    Alice  Charlie       2\n",
      "2      Bob    Alice       6\n",
      "3      Bob  Charlie       3\n",
      "4  Charlie    Alice       4\n",
      "\n",
      "Undirected Edge List:\n",
      "  source   target  weight\n",
      "0  Alice      Bob      12\n",
      "1  Alice  Charlie       6\n",
      "2    Bob  Charlie       3\n",
      "\n",
      "============================================================\n",
      "TEST 2: Create Adjacency Matrix\n",
      "============================================================\n",
      "\n",
      "Adjacency Matrix (weighted):\n",
      "         Alice  Bob  Charlie\n",
      "Alice      0.0  6.0      2.0\n",
      "Bob        6.0  0.0      3.0\n",
      "Charlie    4.0  0.0      0.0\n",
      "\n",
      "Edge List from Adjacency Matrix:\n",
      "    source   target  weight\n",
      "0    Alice      Bob     6.0\n",
      "1    Alice  Charlie     2.0\n",
      "2      Bob    Alice     6.0\n",
      "3      Bob  Charlie     3.0\n",
      "4  Charlie    Alice     4.0\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "id": "odqsf8pbow9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:05:02.976850Z",
     "iopub.status.busy": "2025-10-16T17:05:02.976434Z",
     "iopub.status.idle": "2025-10-16T17:05:02.982988Z",
     "shell.execute_reply": "2025-10-16T17:05:02.982235Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:53.205117Z",
     "start_time": "2025-10-16T22:49:53.200589Z"
    }
   },
   "source": [
    "import importlib\n",
    "from sociopathit.analyses import network as network_module\n",
    "\n",
    "importlib.reload(network_module)\n",
    "from sociopathit.analyses.network import (\n",
    "    create_edgelist, create_adjacency_matrix, cooccurrence_network,\n",
    "    create_bipartite_edgelist, project_bipartite, similarity_network,\n",
    "    correlation_network, network_summary\n",
    ")\n",
    "\n",
    "print(\"Network Module Loaded Successfully\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Module Loaded Successfully\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "id": "37pzjldgrx8",
   "source": "# Test 7: Sentiment Analysis (Lexicon-based)\nprint(\"=\" * 60)\nprint(\"TEST 7: Sentiment Analysis - Lexicon Method\")\nprint(\"=\" * 60)\n\ntest_texts = [\n    \"This is an amazing and wonderful product! I love it!\",\n    \"This is terrible, awful, and horrible. I hate it.\",\n    \"This is okay. Nothing special.\",\n    \"The weather today is nice.\"\n]\n\ntry:\n    analyzer = SentimentAnalyzer(method='lexicon')\n    \n    for text in test_texts:\n        result = analyzer.analyze(text)\n        print(f\"\\nText: {text}\")\n        print(f\"Sentiment: {result['label']} (score: {result['score']:.3f})\")\n    \n    print(\"\\nâœ“ Lexicon-based sentiment analysis tests passed\")\n    \nexcept Exception as e:\n    print(f\"âœ— Lexicon-based sentiment analysis test failed: {e}\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:53.318503Z",
     "start_time": "2025-10-16T22:49:53.314591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 7: Sentiment Analysis - Lexicon Method\n",
      "============================================================\n",
      "\n",
      "Text: This is an amazing and wonderful product! I love it!\n",
      "Sentiment: POSITIVE (score: 0.300)\n",
      "\n",
      "Text: This is terrible, awful, and horrible. I hate it.\n",
      "Sentiment: NEGATIVE (score: 0.444)\n",
      "\n",
      "Text: This is okay. Nothing special.\n",
      "Sentiment: NEUTRAL (score: 0.000)\n",
      "\n",
      "Text: The weather today is nice.\n",
      "Sentiment: NEUTRAL (score: 0.000)\n",
      "\n",
      "âœ“ Lexicon-based sentiment analysis tests passed\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "id": "0opzxhoraoz",
   "source": "# Test 8: Sentiment Analysis (Transformer-based)\nprint(\"=\" * 60)\nprint(\"TEST 8: Sentiment Analysis - Transformer Method\")\nprint(\"=\" * 60)\n\nif not HAS_TRANSFORMERS:\n    print(\"âš  Transformers library not available. Skipping transformer tests.\")\n    print(\"  Install with: pip install transformers torch\")\nelse:\n    test_texts = [\n        \"This is an amazing and wonderful product! I love it!\",\n        \"This is terrible and disappointing. Very bad experience.\",\n        \"The item is okay, nothing particularly special.\"\n    ]\n    \n    try:\n        print(\"Loading sentiment analysis model (this may take a moment)...\")\n        analyzer = SentimentAnalyzer(method='transformer')\n        \n        print(\"\\nAnalyzing texts...\")\n        for text in test_texts:\n            result = analyzer.analyze(text)\n            print(f\"\\nText: {text}\")\n            print(f\"Sentiment: {result['label']} (confidence: {result['score']:.3f})\")\n        \n        # Test batch processing\n        print(\"\\n\\nTesting batch processing...\")\n        results = analyzer.analyze(test_texts)\n        print(f\"Processed {len(results)} texts in batch\")\n        \n        print(\"\\nâœ“ Transformer-based sentiment analysis tests passed\")\n        \n    except Exception as e:\n        print(f\"âœ— Transformer-based sentiment analysis test failed: {e}\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:54.175525Z",
     "start_time": "2025-10-16T22:49:53.475633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 8: Sentiment Analysis - Transformer Method\n",
      "============================================================\n",
      "Loading sentiment analysis model (this may take a moment)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing texts...\n",
      "\n",
      "Text: This is an amazing and wonderful product! I love it!\n",
      "Sentiment: POSITIVE (confidence: 1.000)\n",
      "\n",
      "Text: This is terrible and disappointing. Very bad experience.\n",
      "Sentiment: NEGATIVE (confidence: 1.000)\n",
      "\n",
      "Text: The item is okay, nothing particularly special.\n",
      "Sentiment: NEGATIVE (confidence: 0.970)\n",
      "\n",
      "\n",
      "Testing batch processing...\n",
      "Processed 3 texts in batch\n",
      "\n",
      "âœ“ Transformer-based sentiment analysis tests passed\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "id": "jujkl8jjsue",
   "source": "# Test 9: BERT Embeddings\nprint(\"=\" * 60)\nprint(\"TEST 9: BERT Embeddings\")\nprint(\"=\" * 60)\n\nif not HAS_TRANSFORMERS:\n    print(\"âš  Transformers library not available. Skipping BERT tests.\")\n    print(\"  Install with: pip install transformers torch\")\nelse:\n    test_texts = [\n        \"The cat is sleeping on the couch.\",\n        \"A feline is resting on the sofa.\",\n        \"Dogs are playing in the park.\"\n    ]\n    \n    try:\n        print(\"Loading BERT model (this may take a moment)...\")\n        bert_model = BERTModel(model_name='bert-base-uncased', task='embedding')\n        \n        print(\"\\nGenerating embeddings...\")\n        embeddings = bert_model.get_embeddings(test_texts, pooling='mean')\n        print(f\"Embeddings shape: {embeddings.shape}\")\n        print(f\"First embedding (first 10 dims): {embeddings[0][:10]}\")\n        \n        # Test similarity\n        print(\"\\n\\nTesting semantic similarity...\")\n        sim_12 = bert_model.similarity(test_texts[0], test_texts[1])\n        sim_13 = bert_model.similarity(test_texts[0], test_texts[2])\n        \n        print(f\"Similarity between texts 1 and 2 (similar meaning): {sim_12:.3f}\")\n        print(f\"Similarity between texts 1 and 3 (different meaning): {sim_13:.3f}\")\n        \n        if sim_12 > sim_13:\n            print(\"âœ“ BERT correctly identified similar texts as more similar\")\n        else:\n            print(\"âš  Unexpected similarity scores\")\n        \n        print(\"\\nâœ“ BERT embeddings tests passed\")\n        \n    except Exception as e:\n        print(f\"âœ— BERT embeddings test failed: {e}\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:55.531809Z",
     "start_time": "2025-10-16T22:49:54.247916Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 9: BERT Embeddings\n",
      "============================================================\n",
      "Loading BERT model (this may take a moment)...\n",
      "\n",
      "Generating embeddings...\n",
      "Embeddings shape: (3, 768)\n",
      "First embedding (first 10 dims): [ 0.0578401  -0.27792972 -0.01247833  0.07429158  0.5953165  -0.7032491\n",
      " -0.2844429   0.5824173  -0.10914177 -0.353179  ]\n",
      "\n",
      "\n",
      "Testing semantic similarity...\n",
      "Similarity between texts 1 and 2 (similar meaning): 0.839\n",
      "Similarity between texts 1 and 3 (different meaning): 0.801\n",
      "âœ“ BERT correctly identified similar texts as more similar\n",
      "\n",
      "âœ“ BERT embeddings tests passed\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "id": "v96c4g6hw98",
   "source": "# Test 10: Ollama Integration\nprint(\"=\" * 60)\nprint(\"TEST 10: Ollama Integration\")\nprint(\"=\" * 60)\n\nif not HAS_REQUESTS:\n    print(\"âš  Requests library not available. Skipping Ollama tests.\")\n    print(\"  Install with: pip install requests\")\nelse:\n    print(\"âš  Note: Ollama tests require a running Ollama server at localhost:11434\")\n    print(\"   If Ollama is not running, these tests will be skipped.\")\n    \n    try:\n        classifier = OllamaClassifier(model='llama2')\n        \n        # Quick test to see if Ollama is available\n        print(\"\\nTesting Ollama connection...\")\n        test_result = classifier.classify(\n            text=\"This is a test.\",\n            categories=[\"test\", \"production\"]\n        )\n        \n        print(\"âœ“ Ollama is available!\")\n        \n        # Test classification\n        print(\"\\n\\nTesting text classification...\")\n        test_texts = [\n            \"I love this product! It's amazing!\",\n            \"This is terrible and doesn't work at all.\",\n            \"It's okay, nothing special.\"\n        ]\n        \n        categories = [\"positive\", \"negative\", \"neutral\"]\n        \n        for text in test_texts:\n            result = classifier.classify(text, categories)\n            print(f\"\\nText: {text}\")\n            print(f\"Category: {result['category']}\")\n        \n        # Test entity extraction\n        print(\"\\n\\nTesting entity extraction...\")\n        text = \"Apple Inc. was founded by Steve Jobs in Cupertino, California.\"\n        entities = classifier.extract_entities(text)\n        print(f\"\\nText: {text}\")\n        print(\"Entities:\")\n        for entity in entities:\n            print(f\"  - {entity['text']} ({entity['type']})\")\n        \n        # Test summarization\n        print(\"\\n\\nTesting summarization...\")\n        long_text = \"\"\"\n        Machine learning is a subset of artificial intelligence that focuses on the\n        development of algorithms and statistical models that enable computers to\n        improve their performance on tasks through experience. Instead of being\n        explicitly programmed, machine learning systems learn from data.\n        \"\"\"\n        summary = classifier.summarize(long_text, max_length=30)\n        print(f\"\\nOriginal length: {len(long_text.split())} words\")\n        print(f\"Summary: {summary}\")\n        print(f\"Summary length: {len(summary.split())} words\")\n        \n        print(\"\\nâœ“ Ollama integration tests passed\")\n        \n    except RuntimeError as e:\n        if \"Ollama API call failed\" in str(e):\n            print(f\"\\nâš  Ollama server not available. Skipping Ollama tests.\")\n            print(\"   To test Ollama functionality, start the Ollama server and run again.\")\n        else:\n            print(f\"\\nâœ— Ollama integration test failed: {e}\")\n    except Exception as e:\n        print(f\"\\nâœ— Ollama integration test failed: {e}\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:57.651687Z",
     "start_time": "2025-10-16T22:49:55.604510Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 10: Ollama Integration\n",
      "============================================================\n",
      "âš  Note: Ollama tests require a running Ollama server at localhost:11434\n",
      "   If Ollama is not running, these tests will be skipped.\n",
      "\n",
      "Testing Ollama connection...\n",
      "\n",
      "âš  Ollama server not available. Skipping Ollama tests.\n",
      "   To test Ollama functionality, start the Ollama server and run again.\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "cell_type": "markdown",
   "id": "hvu49pkczag",
   "metadata": {},
   "source": [
    "<a id='network'></a>\n",
    "# 10. Network Data Preparation\n",
    "\n",
    "Edge lists, adjacency matrices, co-occurrence networks, bipartite networks with the `network` module."
   ]
  },
  {
   "cell_type": "code",
   "id": "om4qbj86gd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:05:02.986822Z",
     "iopub.status.busy": "2025-10-16T17:05:02.986453Z",
     "iopub.status.idle": "2025-10-16T17:05:03.022949Z",
     "shell.execute_reply": "2025-10-16T17:05:03.021931Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:57.728745Z",
     "start_time": "2025-10-16T22:49:57.707300Z"
    }
   },
   "source": [
    "# Test 5: Topic Modeling\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 5: Topic Modeling (LDA)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Create more texts for better topic modeling\n",
    "    extended_texts = sample_texts + [\n",
    "        \"Python programming language is widely used for data analysis and machine learning tasks.\",\n",
    "        \"Statistical analysis helps in understanding data patterns and relationships.\",\n",
    "        \"Deep learning models require large amounts of training data.\",\n",
    "        \"Text classification is an important task in natural language processing.\",\n",
    "        \"Data visualization makes it easier to communicate insights from analysis.\"\n",
    "    ]\n",
    "    \n",
    "    topic_model = TopicModel(n_topics=3, method='lda', random_state=42)\n",
    "    topic_model.fit(extended_texts)\n",
    "    \n",
    "    topics = topic_model.get_topics(n_words=5)\n",
    "    doc_topics = topic_model.get_document_topics()\n",
    "    \n",
    "    print(f\"\\nTopics (top 5 words each):\")\n",
    "    print(topics)\n",
    "    \n",
    "    print(f\"\\nDocument-Topic Distribution (first 5 documents):\")\n",
    "    print(doc_topics.head())\n",
    "    \n",
    "    print(f\"\\nDominant topics for first 5 documents:\")\n",
    "    print(topic_model.get_dominant_topic().head())\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"\\nSkipping topic modeling test: {e}\")\n",
    "    print(\"scikit-learn is required for this feature\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 5: Topic Modeling (LDA)\n",
      "============================================================\n",
      "\n",
      "Topics (top 5 words each):\n",
      "    Topic 1      Topic 2     Topic 3\n",
      "0      data         data  processing\n",
      "1  analysis           of    language\n",
      "2      text      amounts          is\n",
      "3       and        large     natural\n",
      "4       for  statistical          an\n",
      "\n",
      "Document-Topic Distribution (first 5 documents):\n",
      "    Topic 1   Topic 2   Topic 3\n",
      "0  0.962141  0.018852  0.019007\n",
      "1  0.021977  0.021540  0.956482\n",
      "2  0.956776  0.022576  0.020647\n",
      "3  0.950695  0.025135  0.024170\n",
      "4  0.957404  0.020551  0.022045\n",
      "\n",
      "Dominant topics for first 5 documents:\n",
      "0    Topic 1\n",
      "1    Topic 3\n",
      "2    Topic 1\n",
      "3    Topic 1\n",
      "4    Topic 1\n",
      "dtype: object\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "id": "5ajzc6mbpf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:05:03.025597Z",
     "iopub.status.busy": "2025-10-16T17:05:03.025110Z",
     "iopub.status.idle": "2025-10-16T17:05:03.036293Z",
     "shell.execute_reply": "2025-10-16T17:05:03.035428Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:57.812321Z",
     "start_time": "2025-10-16T22:49:57.806782Z"
    }
   },
   "source": [
    "# Test 4: TF-IDF Matrix\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 4: TF-IDF Vectorization\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    tfidf_df, vectorizer = create_tfidf_matrix(sample_texts, max_features=20)\n",
    "    \n",
    "    print(f\"\\nTF-IDF Matrix Shape: {tfidf_df.shape}\")\n",
    "    print(f\"Number of features: {len(vectorizer.get_feature_names_out())}\")\n",
    "    \n",
    "    # Get top terms overall\n",
    "    from sociopathit.analyses.text_analysis import get_top_tfidf_terms\n",
    "    top_terms = get_top_tfidf_terms(tfidf_df, n_terms=10)\n",
    "    \n",
    "    print(f\"\\nTop 10 TF-IDF Terms:\")\n",
    "    for term, score in top_terms.items():\n",
    "        print(f\"  {term}: {score:.3f}\")\n",
    "except ImportError as e:\n",
    "    print(f\"\\nSkipping TF-IDF test: {e}\")\n",
    "    print(\"scikit-learn is required for this feature\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 4: TF-IDF Vectorization\n",
      "============================================================\n",
      "\n",
      "TF-IDF Matrix Shape: (5, 20)\n",
      "Number of features: 20\n",
      "\n",
      "Top 10 TF-IDF Terms:\n",
      "  data: 0.235\n",
      "  text: 0.181\n",
      "  and: 0.168\n",
      "  patterns: 0.162\n",
      "  of: 0.151\n",
      "  is: 0.146\n",
      "  the: 0.140\n",
      "  language: 0.120\n",
      "  processing: 0.120\n",
      "  science: 0.120\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "id": "o1hp8fn6pd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:05:03.039856Z",
     "iopub.status.busy": "2025-10-16T17:05:03.039457Z",
     "iopub.status.idle": "2025-10-16T17:05:03.045410Z",
     "shell.execute_reply": "2025-10-16T17:05:03.044668Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:57.925703Z",
     "start_time": "2025-10-16T22:49:57.922064Z"
    }
   },
   "source": [
    "# Test 2: Complexity and Readability Scores\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 2: Complexity and Readability Scores\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_text = sample_texts[0]\n",
    "scores = complexity_scores(test_text)\n",
    "\n",
    "print(f\"\\nText: {test_text}\")\n",
    "print(f\"\\nComplexity Metrics:\")\n",
    "for metric, value in scores.items():\n",
    "    print(f\"  {metric}: {value:.2f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 2: Complexity and Readability Scores\n",
      "============================================================\n",
      "\n",
      "Text: The quick brown fox jumps over the lazy dog. This is a simple sentence for testing text analysis.\n",
      "\n",
      "Complexity Metrics:\n",
      "  flesch_reading_ease: 80.20\n",
      "  flesch_kincaid_grade: 4.31\n",
      "  lexical_diversity: 0.94\n",
      "  avg_word_length: 4.44\n",
      "  word_count: 18.00\n",
      "  sentence_count: 3.00\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "id": "srl73bgig4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T17:05:03.048579Z",
     "iopub.status.busy": "2025-10-16T17:05:03.048197Z",
     "iopub.status.idle": "2025-10-16T17:05:03.054082Z",
     "shell.execute_reply": "2025-10-16T17:05:03.053289Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T22:49:58.022298Z",
     "start_time": "2025-10-16T22:49:58.018638Z"
    }
   },
   "source": [
    "# Test 1: Text Cleaning and Preprocessing\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 1: Text Cleaning and Preprocessing\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "text = \"The Quick BROWN Fox!!! Jumps over the lazy dog... 123\"\n",
    "cleaned = clean_text(text, lowercase=True, remove_punctuation=True, remove_numbers=True)\n",
    "tokens = tokenize(cleaned)\n",
    "\n",
    "print(f\"\\nOriginal text: {text}\")\n",
    "print(f\"Cleaned text: {cleaned}\")\n",
    "print(f\"Tokens: {tokens}\")\n",
    "print(f\"Number of tokens: {len(tokens)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 1: Text Cleaning and Preprocessing\n",
      "============================================================\n",
      "\n",
      "Original text: The Quick BROWN Fox!!! Jumps over the lazy dog... 123\n",
      "Cleaned text: the quick brown fox jumps over the lazy dog\n",
      "Tokens: ['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n",
      "Number of tokens: 9\n"
     ]
    }
   ],
   "execution_count": 56
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
